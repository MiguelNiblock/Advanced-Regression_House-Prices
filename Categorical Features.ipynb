{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import cyrtranslit\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection, ensemble, linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://onedrive.live.com/download?cid=62B3CEE436FDB342&resid=62B3CEE436FDB342%21107&authkey=AEh-8Y6p9SC7FK0\",\n",
    "                      compression='zip', parse_dates=[\"activation_date\"])\n",
    "test = pd.read_csv(\"https://onedrive.live.com/download?cid=62B3CEE436FDB342&resid=62B3CEE436FDB342%21106&authkey=AAF_zwBmWjNhNGQ\",\n",
    "                      compression='zip', parse_dates=[\"activation_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Since the test data has no labels, we'll validate with two subsets of train. Lastly we'll use test to generate a submission file and get a public score.\n",
    "\n",
    "## Basic Feature Engineering\n",
    "\n",
    "- Translate all textual features into latin.\n",
    "- Create dummies from categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1503424 entries, 0 to 1503423\n",
      "Data columns (total 18 columns):\n",
      "item_id                 1503424 non-null object\n",
      "user_id                 1503424 non-null object\n",
      "region                  1503424 non-null object\n",
      "city                    1503424 non-null object\n",
      "parent_category_name    1503424 non-null object\n",
      "category_name           1503424 non-null object\n",
      "param_1                 1441848 non-null object\n",
      "param_2                 848882 non-null object\n",
      "param_3                 640859 non-null object\n",
      "title                   1503424 non-null object\n",
      "description             1387148 non-null object\n",
      "price                   1418062 non-null float64\n",
      "item_seq_number         1503424 non-null int64\n",
      "activation_date         1503424 non-null datetime64[ns]\n",
      "user_type               1503424 non-null object\n",
      "image                   1390836 non-null object\n",
      "image_top_1             1390836 non-null float64\n",
      "deal_probability        1503424 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(13)\n",
      "memory usage: 206.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title and description have too many unique values, therefore we won't translate them all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique regions: 28\n",
      "Number of unique cities: 1733\n",
      "Number of unique parent categories: 9\n",
      "Number of unique categories: 47\n",
      "Number of unique descriptions: 1317102\n",
      "Number of unique titles: 788377\n",
      "Number of unique param_1: 371\n",
      "Number of unique param_2: 271\n",
      "Number of unique param_3 1219\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique regions:',len(train.region.value_counts()))\n",
    "print('Number of unique cities:',len(train.city.value_counts()))\n",
    "print('Number of unique parent categories:',len(train.parent_category_name.value_counts()))\n",
    "print('Number of unique categories:',len(train.category_name.value_counts()))\n",
    "print('Number of unique descriptions:',len(train.description.value_counts()))\n",
    "print('Number of unique titles:',len(train.title.value_counts()))\n",
    "print('Number of unique param_1:',len(train.param_1.value_counts()))\n",
    "print('Number of unique param_2:',len(train.param_2.value_counts()))\n",
    "print('Number of unique param_3',len(train.param_3.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description and title have too many unique values,\n",
    "# Therefore this method would take too long.\n",
    "cyr_vars = ['region','city','parent_category_name','category_name',\n",
    "           'param_1','param_2','param_3']\n",
    "\n",
    "for var in cyr_vars:\n",
    "    for dataset in [train,test]:\n",
    "        # Get unique cyrilic vlaues\n",
    "        cyrilic_unique = np.unique(dataset[var].fillna('Blank')).tolist()\n",
    "        # Get unique latin translations\n",
    "        latin_unique = [cyrtranslit.to_latin(string,'ru') for string in cyrilic_unique]\n",
    "\n",
    "        # Put lists in a dictionary\n",
    "        trans_dict = {}\n",
    "        for cyr, lat in zip(cyrilic_unique,latin_unique):\n",
    "            trans_dict[cyr]=lat\n",
    "\n",
    "        # Create a translated list\n",
    "        en_list = []\n",
    "        for key in dataset[var].fillna('Blank'):\n",
    "            en_list.append(trans_dict[key])\n",
    "\n",
    "        # Add english list as column\n",
    "        dataset[str(var)+'_en'] = en_list\n",
    "        dataset.drop(var,axis=1,inplace=True)\n",
    "\n",
    "del cyrilic_unique,latin_unique,trans_dict,en_list,dataset,cyr_vars,var,cyr,lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_en</th>\n",
       "      <th>city_en</th>\n",
       "      <th>parent_category_name_en</th>\n",
       "      <th>category_name_en</th>\n",
       "      <th>param_1_en</th>\n",
       "      <th>param_2_en</th>\n",
       "      <th>param_3_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sverdlovskaja oblast'</td>\n",
       "      <td>Ekaterinburg</td>\n",
       "      <td>Lichnye veszi</td>\n",
       "      <td>Tovary dlja detej i igrushki</td>\n",
       "      <td>Postel'nye prinadlezhnosti</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samarskaja oblast'</td>\n",
       "      <td>Samara</td>\n",
       "      <td>Dlja doma i dachi</td>\n",
       "      <td>Mebel' i inter'er</td>\n",
       "      <td>Drugoe</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rostovskaja oblast'</td>\n",
       "      <td>Rostov-na-Donu</td>\n",
       "      <td>Bytovaja ehlektronika</td>\n",
       "      <td>Audio i video</td>\n",
       "      <td>Video, DVD i Blu-ray pleery</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region_en         city_en parent_category_name_en  \\\n",
       "0  Sverdlovskaja oblast'    Ekaterinburg           Lichnye veszi   \n",
       "1     Samarskaja oblast'          Samara       Dlja doma i dachi   \n",
       "2    Rostovskaja oblast'  Rostov-na-Donu   Bytovaja ehlektronika   \n",
       "\n",
       "               category_name_en                   param_1_en param_2_en  \\\n",
       "0  Tovary dlja detej i igrushki   Postel'nye prinadlezhnosti      Blank   \n",
       "1             Mebel' i inter'er                       Drugoe      Blank   \n",
       "2                 Audio i video  Video, DVD i Blu-ray pleery      Blank   \n",
       "\n",
       "  param_3_en  \n",
       "0      Blank  \n",
       "1      Blank  \n",
       "2      Blank  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_en</th>\n",
       "      <th>city_en</th>\n",
       "      <th>parent_category_name_en</th>\n",
       "      <th>category_name_en</th>\n",
       "      <th>param_1_en</th>\n",
       "      <th>param_2_en</th>\n",
       "      <th>param_3_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volgogradskaja oblast'</td>\n",
       "      <td>Volgograd</td>\n",
       "      <td>Lichnye veszi</td>\n",
       "      <td>Detskaja odezhda i obuv'</td>\n",
       "      <td>Dlja mal'chikov</td>\n",
       "      <td>Obuv'</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sverdlovskaja oblast'</td>\n",
       "      <td>Nizhnjaja Tura</td>\n",
       "      <td>Hobbi i otdyh</td>\n",
       "      <td>Velosipedy</td>\n",
       "      <td>Dorozhnye</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novosibirskaja oblast'</td>\n",
       "      <td>Berdsk</td>\n",
       "      <td>Bytovaja ehlektronika</td>\n",
       "      <td>Audio i video</td>\n",
       "      <td>Televizory i proektory</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region_en         city_en parent_category_name_en  \\\n",
       "0  Volgogradskaja oblast'       Volgograd           Lichnye veszi   \n",
       "1   Sverdlovskaja oblast'  Nizhnjaja Tura           Hobbi i otdyh   \n",
       "2  Novosibirskaja oblast'          Berdsk   Bytovaja ehlektronika   \n",
       "\n",
       "           category_name_en              param_1_en param_2_en param_3_en  \n",
       "0  Detskaja odezhda i obuv'         Dlja mal'chikov      Obuv'         25  \n",
       "1                Velosipedy               Dorozhnye      Blank      Blank  \n",
       "2             Audio i video  Televizory i proektory      Blank      Blank  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See latin translations\n",
    "print('Train Data:')\n",
    "display(train.iloc[:3,-7:])\n",
    "print(\"\")\n",
    "print('Test Data:')\n",
    "display(test.iloc[:3,-7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies\n",
    "### City Features\n",
    "- The number of unique cities in train is too large (1700) and leads to `MemoryError`. Let's pick a subset of those cities. The most useful might be those which appear in both train and test. Cities appearing only in train won't help predict anything in test that regards the city variable, and listings from cities which appear only in test can't be predicted with train information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store features selected\n",
    "train_features = pd.DataFrame(index=train.index)\n",
    "test_features = pd.DataFrame(index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comon values: 1625\n",
      "N Listings in both sets from unique common values: 2011447\n",
      "New features: (1503424, 150)\n"
     ]
    }
   ],
   "source": [
    "# Find popular common values, create dummies, and get n_features\n",
    "\n",
    "# Find unique common values in both sets\n",
    "var = 'city_en'\n",
    "test_unique = test[var].unique()\n",
    "train_unique = train[var].unique()\n",
    "common = [unique for unique in train_unique if unique in test_unique]\n",
    "del test_unique,train_unique\n",
    "print('Unique comon values:',len(common))\n",
    "\n",
    "# Find the top popular of those common values\n",
    "train_common = train[train[var].apply(lambda x: x in common)][var]\n",
    "test_common = test[test[var].apply(lambda x: x in common)][var]\n",
    "traintest_common = train_common.append(test_common)\n",
    "print('N Listings in both sets from unique common values:',traintest_common.shape[0])\n",
    "\n",
    "top_common = traintest_common.value_counts()[:150].keys().tolist()\n",
    "del common,train_common,test_common,traintest_common\n",
    "\n",
    "# Make dummies from top common values\n",
    "new_features = pd.DataFrame(index=train.index)\n",
    "for common in top_common:\n",
    "    new_features[str(common)] = np.where(train[var] == common,1,0)\n",
    "del top_common\n",
    "print('New features:',new_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without feature selection: 0.00230186731009178\n",
      "N Features to select: 13\n"
     ]
    }
   ],
   "source": [
    "# Baseline score without feature selection\n",
    "model = linear_model.LinearRegression()\n",
    "cv = model_selection.cross_val_score(model,new_features,train.deal_probability,cv=3)\n",
    "score = np.mean(cv)\n",
    "print('Score without feature selection:',score)\n",
    "\n",
    "# Let the number of features depend on the potential score\n",
    "n_features = int(len(new_features.columns)*(score**0.4))\n",
    "print('N Features to select:',n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Feature Selection Techniques\n",
    "- **Techniques:** Feature Importances, Lasso L1, Ridge, F Regression.\n",
    "- Notice that feature importances will be fit with less data due to time consumption on tree-based models. It's hard to tell if it'd perform better with full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=['Importances','CoefLasso','CoefRidge','FRegression'],columns=['Score','Selector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Feature Importances: 0.0012934890283679372\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel on Tree-based feature importances\n",
    "selector1 = feature_selection.SelectFromModel(\n",
    "    ensemble.ExtraTreesRegressor(),\n",
    "    threshold=-np.inf,\n",
    "    max_features=n_features)\n",
    "\n",
    "# Undersample dataset to reduce time\n",
    "index = np.random.choice(len(train),size=int(len(train)/7))\n",
    "selector1.fit(new_features.iloc[index],train.iloc[index].deal_probability)\n",
    "selection = new_features.iloc[:,selector1.get_support()]\n",
    "\n",
    "# Score of these features\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Feature Importances:',np.mean(cv))\n",
    "results.loc['Importances','Score'] = np.mean(cv)\n",
    "results.loc['Importances','Selector']=selector1\n",
    "del index, selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Lasso Coefs: 0.0009250099923582278\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Lasso coefs\n",
    "selector2 = feature_selection.SelectFromModel(\n",
    "    linear_model.Lasso(),\n",
    "    threshold=-np.inf,\n",
    "    max_features=n_features)\n",
    "selector2.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector2.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Lasso Coefs:',np.mean(cv))\n",
    "results.loc['CoefLasso','Score'] = np.mean(cv)\n",
    "results.loc['CoefLasso','Selector']=selector2\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by f_regression: 0.0013005899234387701\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectKBest from f_regression\n",
    "selector3 = feature_selection.SelectKBest(\n",
    "    feature_selection.f_regression,\n",
    "    k=n_features)\n",
    "selector3.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector3.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by f_regression:',np.mean(cv))\n",
    "results.loc['FRegression','Score'] = np.mean(cv)\n",
    "results.loc['FRegression','Selector']=selector3\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Ridge Coefs: 0.0007214362864883158\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Ridge coefs\n",
    "selector4 = feature_selection.SelectFromModel(\n",
    "    linear_model.Ridge(),\n",
    "    threshold=-np.inf,\n",
    "    max_features=n_features)\n",
    "selector4.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector4.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Ridge Coefs:',np.mean(cv))\n",
    "results.loc['CoefRidge','Score'] = np.mean(cv)\n",
    "results.loc['CoefRidge','Selector']=selector4\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FRegression</th>\n",
       "      <td>0.00130059</td>\n",
       "      <td>SelectKBest(k=13, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Importances</th>\n",
       "      <td>0.00129349</td>\n",
       "      <td>SelectFromModel(estimator=ExtraTreesRegressor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefLasso</th>\n",
       "      <td>0.00092501</td>\n",
       "      <td>SelectFromModel(estimator=Lasso(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefRidge</th>\n",
       "      <td>0.000721436</td>\n",
       "      <td>SelectFromModel(estimator=Ridge(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Score                                           Selector\n",
       "FRegression   0.00130059  SelectKBest(k=13, score_func=<function f_regre...\n",
       "Importances   0.00129349  SelectFromModel(estimator=ExtraTreesRegressor(...\n",
       "CoefLasso     0.00092501  SelectFromModel(estimator=Lasso(alpha=1.0, cop...\n",
       "CoefRidge    0.000721436  SelectFromModel(estimator=Ridge(alpha=1.0, cop..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.sort_values(by='Score',ascending=False))\n",
    "best = results.sort_values(by='Score',ascending=False).iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- City features are ordered by descending popularity. Surprisingly, the Boolean mask shows many `False` at the beginning of the list. This means the cities with most popularity aren't necessarily the ones that add most predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the best features\n",
    "new_features = new_features.loc[:,best.get_support()]\n",
    "# Add new features to train_features\n",
    "train_features = train_features.join(new_features)\n",
    "# Variable no longer needed\n",
    "train.drop(var,axis=1,inplace=True)\n",
    "\n",
    "features = new_features.columns.tolist()\n",
    "\n",
    "# Create features \n",
    "for f in features:\n",
    "    test_features[str(f)] = np.where(test[var] == f,1,0)\n",
    "test.drop(var,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 17)\n",
      "(508438, 16)\n",
      "(1503424, 13)\n",
      "(508438, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features: Param_1, 2 & 3\n",
    "- Features from these are challenging because some values repeat in more than one of these variables. Therefore when creating dummies, column names overlap. Adding prefixes helps but some values exist only in train or test set, therefore each set ends with a different number of features. The solution is to gather a custom list of values to create features from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comon values: 362\n",
      "N Listings in both sets from unique common values: 2011838\n",
      "New features: (1503424, 150)\n"
     ]
    }
   ],
   "source": [
    "# Find popular common values, create dummies\n",
    "\n",
    "# Find unique common values in both sets\n",
    "var = 'param_1_en'\n",
    "test_unique = test[var].unique()\n",
    "train_unique = train[var].unique()\n",
    "common = [unique for unique in train_unique if unique in test_unique]\n",
    "del test_unique,train_unique\n",
    "print('Unique comon values:',len(common))\n",
    "\n",
    "# Find the top popular of those common values\n",
    "train_common = train[train[var].apply(lambda x: x in common)][var]\n",
    "test_common = test[test[var].apply(lambda x: x in common)][var]\n",
    "traintest_common = train_common.append(test_common)\n",
    "print('N Listings in both sets from unique common values:',traintest_common.shape[0])\n",
    "\n",
    "top_common = traintest_common.value_counts()[:150].keys().tolist()\n",
    "del common,train_common,test_common,traintest_common\n",
    "\n",
    "# Make dummies from top common values\n",
    "new_features = pd.DataFrame(index=train.index)\n",
    "for common in top_common:\n",
    "    new_features[str(common)] = np.where(train[var] == common,1,0)\n",
    "del top_common\n",
    "print('New features:',new_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without feature selection: 0.15360099276817882\n",
      "N Features to select: 70\n"
     ]
    }
   ],
   "source": [
    "cv = model_selection.cross_val_score(model,new_features,train.deal_probability,cv=3)\n",
    "score = np.mean(cv)\n",
    "print('Score without feature selection:',score)\n",
    "\n",
    "# Let the number of features depend on the potential score\n",
    "n_features = int(len(new_features.columns)*(score**0.4))\n",
    "print('N Features to select:',n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Feature Importances: 0.1497378230196806\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel on Tree-based feature importances\n",
    "selector1.max_features=n_features\n",
    "index = np.random.choice(len(train),size=int(len(train)/7))\n",
    "selector1.fit(new_features.iloc[index],train.iloc[index].deal_probability)\n",
    "selection = new_features.iloc[:,selector1.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Feature Importances:',np.mean(cv))\n",
    "results.loc['Importances','Score'] = np.mean(cv)\n",
    "results.loc['Importances','Selector']=selector1\n",
    "del index, selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Coefs: 0.1354066173414947\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Lasso coefs\n",
    "selector2.max_features=n_features\n",
    "selector2.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector2.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Coefs:',np.mean(cv))\n",
    "results.loc['CoefLasso','Score'] = np.mean(cv)\n",
    "results.loc['CoefLasso','Selector']=selector2\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by f_regression: 0.14950788474007837\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectKBest from f_regression\n",
    "selector3.k=n_features\n",
    "selector3.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector3.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by f_regression:',np.mean(cv))\n",
    "results.loc['FRegression','Score'] = np.mean(cv)\n",
    "results.loc['FRegression','Selector']=selector3\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Ridge Coefs: 0.13924541531070386\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Ridge coefs\n",
    "selector4.max_features=n_features\n",
    "selector4.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector4.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Ridge Coefs:',np.mean(cv))\n",
    "results.loc['CoefRidge','Score'] = np.mean(cv)\n",
    "results.loc['CoefRidge','Selector']=selector4\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Importances</th>\n",
       "      <td>0.149738</td>\n",
       "      <td>SelectFromModel(estimator=ExtraTreesRegressor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRegression</th>\n",
       "      <td>0.149508</td>\n",
       "      <td>SelectKBest(k=70, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefRidge</th>\n",
       "      <td>0.139245</td>\n",
       "      <td>SelectFromModel(estimator=Ridge(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefLasso</th>\n",
       "      <td>0.135407</td>\n",
       "      <td>SelectFromModel(estimator=Lasso(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Score                                           Selector\n",
       "Importances  0.149738  SelectFromModel(estimator=ExtraTreesRegressor(...\n",
       "FRegression  0.149508  SelectKBest(k=70, score_func=<function f_regre...\n",
       "CoefRidge    0.139245  SelectFromModel(estimator=Ridge(alpha=1.0, cop...\n",
       "CoefLasso    0.135407  SelectFromModel(estimator=Lasso(alpha=1.0, cop..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.sort_values(by='Score',ascending=False))\n",
    "best = results.sort_values(by='Score',ascending=False).iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extra trees regressor gave the best set of features.\n",
    "- Compared to the city variable, `param_1` has very strong predictive power. Knowing this alone, we can predict the deal probability with ~15% accuracy.\n",
    "- By selecting 70 out of 150 features, we only lose ~1% predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False,  True, False,  True, False,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False,  True,  True,  True, False,  True, False,  True, False,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "        True, False, False, False,  True,  True, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `True`s cleary cluster along the beginning of the list, so since features are ordered by popularity, high variance correlates with feature importance. However, the presence of some `True`s along the end of the list signifies that some important features also had very low variance.\n",
    "- Note that popularity isn't always associated with feature importance. For the city variable, there were many more unpopular cities selected as important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the best features\n",
    "new_features = new_features.loc[:,best.get_support()]\n",
    "# Add new features to train_features\n",
    "train_features = train_features.join(new_features)\n",
    "\n",
    "# Create test features \n",
    "features = new_features.columns.tolist()\n",
    "for f in features:\n",
    "    test_features[str(f)] = np.where(test[var] == f,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 17)\n",
      "(508438, 16)\n",
      "(1503424, 83)\n",
      "(508438, 83)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(var,axis=1,inplace=True)\n",
    "test.drop(var,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comon values: 250\n",
      "N Listings in both sets from unique common values: 2011801\n",
      "New features: (1503424, 150)\n"
     ]
    }
   ],
   "source": [
    "# Find popular common values, create dummies\n",
    "\n",
    "# Find unique common values in both sets\n",
    "var = 'param_2_en'\n",
    "test_unique = test[var].unique()\n",
    "train_unique = train[var].unique()\n",
    "common = [unique for unique in train_unique if unique in test_unique]\n",
    "del test_unique,train_unique\n",
    "print('Unique comon values:',len(common))\n",
    "\n",
    "# Find the top popular of those common values\n",
    "train_common = train[train[var].apply(lambda x: x in common)][var]\n",
    "test_common = test[test[var].apply(lambda x: x in common)][var]\n",
    "traintest_common = train_common.append(test_common)\n",
    "print('N Listings in both sets from unique common values:',traintest_common.shape[0])\n",
    "\n",
    "top_common = traintest_common.value_counts()[:150].keys().tolist()\n",
    "del common,train_common,test_common,traintest_common\n",
    "\n",
    "# Make dummies from top common values\n",
    "new_features = pd.DataFrame(index=train.index)\n",
    "for common in top_common:\n",
    "    new_features[str(common)] = np.where(train[var] == common,1,0)\n",
    "del top_common\n",
    "print('New features:',new_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without feature selection: 0.12048693867067557\n",
      "N Features to select: 64\n"
     ]
    }
   ],
   "source": [
    "cv = model_selection.cross_val_score(model,new_features,train.deal_probability,cv=3)\n",
    "score = np.mean(cv)\n",
    "print('Score without feature selection:',score)\n",
    "\n",
    "# Let the number of features depend on the potential score\n",
    "n_features = int(len(new_features.columns)*(score**0.4))\n",
    "print('N Features to select:',n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Feature Importances: 0.11498425859927286\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel on Tree-based feature importances\n",
    "selector1.max_features=n_features\n",
    "index = np.random.choice(len(train),size=int(len(train)/7))\n",
    "selector1.fit(new_features.iloc[index],train.iloc[index].deal_probability)\n",
    "selection = new_features.iloc[:,selector1.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Feature Importances:',np.mean(cv))\n",
    "results.loc['Importances','Score'] = np.mean(cv)\n",
    "results.loc['Importances','Selector']=selector1\n",
    "del index, selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Coefs: 0.10801743541266817\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Lasso coefs\n",
    "selector2.max_features=n_features\n",
    "selector2.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector2.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Coefs:',np.mean(cv))\n",
    "results.loc['CoefLasso','Score'] = np.mean(cv)\n",
    "results.loc['CoefLasso','Selector']=selector2\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by f_regression: 0.1155751083634029\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectKBest from f_regression\n",
    "selector3.k=n_features\n",
    "selector3.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector3.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by f_regression:',np.mean(cv))\n",
    "results.loc['FRegression','Score'] = np.mean(cv)\n",
    "results.loc['FRegression','Selector']=selector3\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Ridge Coefs: 0.09184644501403638\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Ridge coefs\n",
    "selector4.max_features=n_features\n",
    "selector4.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector4.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Ridge Coefs:',np.mean(cv))\n",
    "results.loc['CoefRidge','Score'] = np.mean(cv)\n",
    "results.loc['CoefRidge','Selector']=selector4\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FRegression</th>\n",
       "      <td>0.115575</td>\n",
       "      <td>SelectKBest(k=64, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Importances</th>\n",
       "      <td>0.114984</td>\n",
       "      <td>SelectFromModel(estimator=ExtraTreesRegressor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefLasso</th>\n",
       "      <td>0.108017</td>\n",
       "      <td>SelectFromModel(estimator=Lasso(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefRidge</th>\n",
       "      <td>0.0918464</td>\n",
       "      <td>SelectFromModel(estimator=Ridge(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Score                                           Selector\n",
       "FRegression   0.115575  SelectKBest(k=64, score_func=<function f_regre...\n",
       "Importances   0.114984  SelectFromModel(estimator=ExtraTreesRegressor(...\n",
       "CoefLasso     0.108017  SelectFromModel(estimator=Lasso(alpha=1.0, cop...\n",
       "CoefRidge    0.0918464  SelectFromModel(estimator=Ridge(alpha=1.0, cop..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.sort_values(by='Score',ascending=False))\n",
    "best = results.sort_values(by='Score',ascending=False).iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features to train_features\n",
    "new_features = new_features.loc[:,best.get_support()]\n",
    "train_features = train_features.join(new_features,lsuffix=var)\n",
    "\n",
    "# Add same features to test\n",
    "features = new_features.columns.tolist()\n",
    "new_features = pd.DataFrame(index=test.index)\n",
    "for f in features:\n",
    "    new_features[str(f)] = np.where(test[var] == f,1,0)\n",
    "\n",
    "test_features = test_features.join(new_features,lsuffix=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 16)\n",
      "(508438, 15)\n",
      "(1503424, 147)\n",
      "(508438, 147)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(var,axis=1,inplace=True)\n",
    "test.drop(var,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comon values: 917\n",
      "N Listings in both sets from unique common values: 2011112\n",
      "New features: (1503424, 150)\n"
     ]
    }
   ],
   "source": [
    "# Find popular common values, create dummies\n",
    "\n",
    "# Find unique common values in both sets\n",
    "var = 'param_3_en'\n",
    "test_unique = test[var].unique()\n",
    "train_unique = train[var].unique()\n",
    "common = [unique for unique in train_unique if unique in test_unique]\n",
    "del test_unique,train_unique\n",
    "print('Unique comon values:',len(common))\n",
    "\n",
    "# Find the top popular of those common values\n",
    "train_common = train[train[var].apply(lambda x: x in common)][var]\n",
    "test_common = test[test[var].apply(lambda x: x in common)][var]\n",
    "traintest_common = train_common.append(test_common)\n",
    "print('N Listings in both sets from unique common values:',traintest_common.shape[0])\n",
    "\n",
    "top_common = traintest_common.value_counts()[:150].keys().tolist()\n",
    "del common,train_common,test_common,traintest_common\n",
    "\n",
    "# Make dummies from top common values\n",
    "new_features = pd.DataFrame(index=train.index)\n",
    "for common in top_common:\n",
    "    new_features[str(common)] = np.where(train[var] == common,1,0)\n",
    "del top_common\n",
    "print('New features:',new_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without feature selection: 0.06968941294661561\n",
      "N Features to select: 51\n"
     ]
    }
   ],
   "source": [
    "cv = model_selection.cross_val_score(model,new_features,train.deal_probability,cv=3)\n",
    "score = np.mean(cv)\n",
    "print('Score without feature selection:',score)\n",
    "\n",
    "# Let the number of features depend on the potential score\n",
    "n_features = int(len(new_features.columns)*(score**0.4))\n",
    "print('N Features to select:',n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Feature Importances: 0.061496034688184285\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel on Tree-based feature importances\n",
    "selector1.max_features=n_features\n",
    "index = np.random.choice(len(train),size=int(len(train)/7))\n",
    "selector1.fit(new_features.iloc[index],train.iloc[index].deal_probability)\n",
    "selection = new_features.iloc[:,selector1.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Feature Importances:',np.mean(cv))\n",
    "results.loc['Importances','Score'] = np.mean(cv)\n",
    "results.loc['Importances','Selector']=selector1\n",
    "del index, selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Coefs: 0.061040005494917914\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Lasso coefs\n",
    "selector2.max_features=n_features\n",
    "selector2.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector2.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Coefs:',np.mean(cv))\n",
    "results.loc['CoefLasso','Score'] = np.mean(cv)\n",
    "results.loc['CoefLasso','Selector']=selector2\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by f_regression: 0.06195594433812276\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectKBest from f_regression\n",
    "selector3.k=n_features\n",
    "selector3.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector3.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by f_regression:',np.mean(cv))\n",
    "results.loc['FRegression','Score'] = np.mean(cv)\n",
    "results.loc['FRegression','Selector']=selector3\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Ridge Coefs: 0.05178232894862874\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Ridge coefs\n",
    "selector4.max_features=n_features\n",
    "selector4.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector4.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Ridge Coefs:',np.mean(cv))\n",
    "results.loc['CoefRidge','Score'] = np.mean(cv)\n",
    "results.loc['CoefRidge','Selector']=selector4\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FRegression</th>\n",
       "      <td>0.0619559</td>\n",
       "      <td>SelectKBest(k=51, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Importances</th>\n",
       "      <td>0.061496</td>\n",
       "      <td>SelectFromModel(estimator=ExtraTreesRegressor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefLasso</th>\n",
       "      <td>0.06104</td>\n",
       "      <td>SelectFromModel(estimator=Lasso(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefRidge</th>\n",
       "      <td>0.0517823</td>\n",
       "      <td>SelectFromModel(estimator=Ridge(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Score                                           Selector\n",
       "FRegression  0.0619559  SelectKBest(k=51, score_func=<function f_regre...\n",
       "Importances   0.061496  SelectFromModel(estimator=ExtraTreesRegressor(...\n",
       "CoefLasso      0.06104  SelectFromModel(estimator=Lasso(alpha=1.0, cop...\n",
       "CoefRidge    0.0517823  SelectFromModel(estimator=Ridge(alpha=1.0, cop..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.sort_values(by='Score',ascending=False))\n",
    "best = results.sort_values(by='Score',ascending=False).iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "       False,  True, False,  True, False, False, False,  True,  True,\n",
       "        True, False,  True, False, False,  True,  True, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True, False,  True,  True,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features to train_features\n",
    "new_features = new_features.loc[:,best.get_support()]\n",
    "train_features = train_features.join(new_features,lsuffix=var)\n",
    "\n",
    "# Add same features to test\n",
    "features = new_features.columns.tolist()\n",
    "new_features = pd.DataFrame(index=test.index)\n",
    "for f in features:\n",
    "    new_features[str(f)] = np.where(test[var] == f,1,0)\n",
    "\n",
    "test_features = test_features.join(new_features,lsuffix=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 15)\n",
      "(508438, 14)\n",
      "(1503424, 198)\n",
      "(508438, 198)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(var,axis=1,inplace=True)\n",
    "test.drop(var,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features: Region, Parent Category, Category\n",
    "- Since these have very few unique values compared to `city` or `param_x`, I'll filter them out at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN\n",
      "Unique values for region_en:  28\n",
      "TEST\n",
      "Unique values for region_en:  28\n",
      "\n",
      "TRAIN\n",
      "Unique values for parent_category_name_en:  9\n",
      "TEST\n",
      "Unique values for parent_category_name_en:  9\n",
      "\n",
      "TRAIN\n",
      "Unique values for category_name_en:  47\n",
      "TEST\n",
      "Unique values for category_name_en:  47\n"
     ]
    }
   ],
   "source": [
    "cat_vars = ['region_en','parent_category_name_en','category_name_en','user_type']\n",
    "for var in cat_vars:\n",
    "    print('\\nTRAIN')\n",
    "    print('Unique values for {}: '.format(var),len(np.unique(train[var])))\n",
    "    print('TEST')\n",
    "    print('Unique values for {}: '.format(var),len(np.unique(test[var])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data in train and test is the same, therefore it's not necessary to find common unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features: (1503424, 84)\n"
     ]
    }
   ],
   "source": [
    "new_features = pd.DataFrame(index=train.index)\n",
    "\n",
    "for var in cat_vars:\n",
    "    for f in np.unique(test[var]):\n",
    "        # Make dummies\n",
    "        new_features[str(f)] = np.where(train[var] == f,1,0)\n",
    "\n",
    "print('New features:',new_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without feature selection: 0.12360141779556955\n",
      "N Features to select: 36\n"
     ]
    }
   ],
   "source": [
    "cv = model_selection.cross_val_score(model,new_features,train.deal_probability,cv=3)\n",
    "score = np.mean(cv)\n",
    "print('Score without feature selection:',score)\n",
    "\n",
    "# Let the number of features depend on the potential score\n",
    "n_features = int(len(new_features.columns)*(score**0.4))\n",
    "print('N Features to select:',n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Feature Importances: 0.12155461164760051\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel on Tree-based feature importances\n",
    "selector1.max_features=n_features\n",
    "index = np.random.choice(len(train),size=int(len(train)/7))\n",
    "selector1.fit(new_features.iloc[index],train.iloc[index].deal_probability)\n",
    "selection = new_features.iloc[:,selector1.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Feature Importances:',np.mean(cv))\n",
    "results.loc['Importances','Score'] = np.mean(cv)\n",
    "results.loc['Importances','Selector']=selector1\n",
    "del index, selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Coefs: 0.09474318099230832\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Lasso coefs\n",
    "selector2.max_features=n_features\n",
    "selector2.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector2.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Coefs:',np.mean(cv))\n",
    "results.loc['CoefLasso','Score'] = np.mean(cv)\n",
    "results.loc['CoefLasso','Selector']=selector2\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by f_regression: 0.1224656102249962\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectKBest from f_regression\n",
    "selector3.k=n_features\n",
    "selector3.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector3.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by f_regression:',np.mean(cv))\n",
    "results.loc['FRegression','Score'] = np.mean(cv)\n",
    "results.loc['FRegression','Selector']=selector3\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection by Ridge Coefs: 0.1221920692494769\n"
     ]
    }
   ],
   "source": [
    "# Score of SelectFromModel from Ridge coefs\n",
    "selector4.max_features=n_features\n",
    "selector4.fit(new_features,train.deal_probability)\n",
    "selection = new_features.iloc[:,selector4.get_support()]\n",
    "cv = model_selection.cross_val_score(model,selection,train.deal_probability,cv=3)\n",
    "print('Selection by Ridge Coefs:',np.mean(cv))\n",
    "results.loc['CoefRidge','Score'] = np.mean(cv)\n",
    "results.loc['CoefRidge','Selector']=selector4\n",
    "del selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FRegression</th>\n",
       "      <td>0.122466</td>\n",
       "      <td>SelectKBest(k=36, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefRidge</th>\n",
       "      <td>0.122192</td>\n",
       "      <td>SelectFromModel(estimator=Ridge(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Importances</th>\n",
       "      <td>0.121555</td>\n",
       "      <td>SelectFromModel(estimator=ExtraTreesRegressor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoefLasso</th>\n",
       "      <td>0.0947432</td>\n",
       "      <td>SelectFromModel(estimator=Lasso(alpha=1.0, cop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Score                                           Selector\n",
       "FRegression   0.122466  SelectKBest(k=36, score_func=<function f_regre...\n",
       "CoefRidge     0.122192  SelectFromModel(estimator=Ridge(alpha=1.0, cop...\n",
       "Importances   0.121555  SelectFromModel(estimator=ExtraTreesRegressor(...\n",
       "CoefLasso    0.0947432  SelectFromModel(estimator=Lasso(alpha=1.0, cop..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.sort_values(by='Score',ascending=False))\n",
    "best = results.sort_values(by='Score',ascending=False).iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True,  True, False,\n",
       "        True, False, False, False, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "        True, False, False,  True, False,  True,  True,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features to train_features\n",
    "new_features = new_features.loc[:,best.get_support()]\n",
    "train_features = train_features.join(new_features,lsuffix=var)\n",
    "\n",
    "# Add same features to test\n",
    "features = new_features.columns.tolist()\n",
    "new_features = pd.DataFrame(index=test.index)\n",
    "for f in features:\n",
    "    new_features[str(f)] = np.where(test[var] == f,1,0)\n",
    "\n",
    "test_features = test_features.join(new_features,lsuffix=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 14)\n",
      "(508438, 13)\n",
      "(1503424, 234)\n",
      "(508438, 234)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    train.drop(var,axis=1,inplace=True)\n",
    "    test.drop(var,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look at the last features added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Krasnojarskij kraj',\n",
       " \"Sverdlovskaja oblast'\",\n",
       " 'Bytovaja ehlektronika',\n",
       " 'Dlja doma i dachi',\n",
       " 'Hobbi i otdyh',\n",
       " 'Lichnye veszi',\n",
       " 'Transport',\n",
       " 'Uslugi',\n",
       " 'ZHivotnye',\n",
       " 'Audio i video',\n",
       " 'Avtomobili',\n",
       " 'Bytovaja tehnika',\n",
       " 'CHasy i ukrashenija',\n",
       " \"Detskaja odezhda i obuv'\",\n",
       " 'Drugie zhivotnye',\n",
       " 'Igry, pristavki i programmy',\n",
       " 'Knigi i zhurnaly',\n",
       " 'Kollekcionirovanie',\n",
       " 'Komnaty',\n",
       " 'Koshki',\n",
       " \"Krasota i zdorov'e\",\n",
       " 'Kvartiry',\n",
       " \"Mebel' i inter'er\",\n",
       " 'Motocikly i mototehnika',\n",
       " \"Muzykal'nye instrumenty\",\n",
       " 'Noutbuki',\n",
       " \"Odezhda, obuv', aksessuary\",\n",
       " 'Predlozhenie uslug',\n",
       " 'Pticy',\n",
       " 'Sobaki',\n",
       " 'Telefony',\n",
       " 'Tovary dlja detej i igrushki',\n",
       " \"Tovary dlja komp'jutera\",\n",
       " 'Velosipedy',\n",
       " 'Vodnyj transport',\n",
       " \"Zemel'nye uchastki\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It seems like only a handful of regions made it with enough importance.\n",
    "- The rest important features are all product categories. Some include telephones, drugs, transportation, electronics, automobiles, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following columns will be worked in a different notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'user_id', 'title', 'description', 'price',\n",
       "       'item_seq_number', 'activation_date', 'user_type', 'image',\n",
       "       'image_top_1', 'deal_probability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_pickle('catfeatures_train.pkl',compression='zip')\n",
    "test_features.to_pickle('catfeatures_test.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_pickle('catfeatures_train.pkl',compression='zip')\n",
    "test_features = pd.read_pickle('catfeatures_test.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('train.pkl',compression='zip')\n",
    "test.to_pickle('test.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train_features', 2814409832),\n",
       " ('train', 1378279207),\n",
       " ('test_features', 951796040),\n",
       " ('test', 478668977),\n",
       " ('new_features', 36082280),\n",
       " ('Pipeline', 1056),\n",
       " ('results', 772),\n",
       " ('features', 352),\n",
       " ('color', 176),\n",
       " ('cv', 120),\n",
       " ('cat_vars', 88),\n",
       " ('ensemble', 80),\n",
       " ('feature_selection', 80),\n",
       " ('lgb', 80),\n",
       " ('linear_model', 80),\n",
       " ('metrics', 80),\n",
       " ('model_selection', 80),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('plt', 80),\n",
       " ('preprocessing', 80),\n",
       " ('sns', 80),\n",
       " ('common', 73),\n",
       " ('f', 67),\n",
       " ('var', 58),\n",
       " ('best', 56),\n",
       " ('model', 56),\n",
       " ('selector1', 56),\n",
       " ('selector2', 56),\n",
       " ('selector3', 56),\n",
       " ('selector4', 56),\n",
       " ('key', 54),\n",
       " ('score', 32),\n",
       " ('n_features', 24)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more Features\n",
    "\n",
    "- (Feature) has description\n",
    "- (Feature) has photo\n",
    "- (Feature) has param 1,2,3\n",
    "- (Feature) has price\n",
    "- (Feature) word count in title, description,\n",
    "- (Feature) population of region\n",
    "- (Feature) string value is unique. title, description, param1, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much can we predict with only categorical features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with current features: 0.16618823247004413\n"
     ]
    }
   ],
   "source": [
    "cv = model_selection.cross_val_score(model,train_features,train.deal_probability,cv=3)\n",
    "score = np.mean(cv)\n",
    "print('Score with current features:',score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
