{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cyrtranslit\n",
    "\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection, ensemble,linear_model\n",
    "import lightgbm as lgb\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://onedrive.live.com/download?cid=62B3CEE436FDB342&resid=62B3CEE436FDB342%21107&authkey=AEh-8Y6p9SC7FK0\",\n",
    "                      compression='zip', parse_dates=[\"activation_date\"])\n",
    "test = pd.read_csv(\"https://onedrive.live.com/download?cid=62B3CEE436FDB342&resid=62B3CEE436FDB342%21106&authkey=AAF_zwBmWjNhNGQ\",\n",
    "                      compression='zip', parse_dates=[\"activation_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Since the test data has no labels, we'll validate with two subsets of train. Lastly we'll use test to generate a submission file and get a public score.\n",
    "\n",
    "## Basic Feature Engineering\n",
    "\n",
    "- Translate all textual features into latin.\n",
    "- Create dummies from categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1503424 entries, 0 to 1503423\n",
      "Data columns (total 18 columns):\n",
      "item_id                 1503424 non-null object\n",
      "user_id                 1503424 non-null object\n",
      "region                  1503424 non-null object\n",
      "city                    1503424 non-null object\n",
      "parent_category_name    1503424 non-null object\n",
      "category_name           1503424 non-null object\n",
      "param_1                 1441848 non-null object\n",
      "param_2                 848882 non-null object\n",
      "param_3                 640859 non-null object\n",
      "title                   1503424 non-null object\n",
      "description             1387148 non-null object\n",
      "price                   1418062 non-null float64\n",
      "item_seq_number         1503424 non-null int64\n",
      "activation_date         1503424 non-null datetime64[ns]\n",
      "user_type               1503424 non-null object\n",
      "image                   1390836 non-null object\n",
      "image_top_1             1390836 non-null float64\n",
      "deal_probability        1503424 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(13)\n",
      "memory usage: 206.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title and description have too many unique values, therefore we won't translate them all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique regions: 28\n",
      "Number of unique cities: 1733\n",
      "Number of unique parent categories: 9\n",
      "Number of unique categories: 47\n",
      "Number of unique descriptions: 1317102\n",
      "Number of unique titles: 788377\n",
      "Number of unique param_1: 371\n",
      "Number of unique param_2: 271\n",
      "Number of unique param_3 1219\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique regions:',len(train.region.value_counts()))\n",
    "print('Number of unique cities:',len(train.city.value_counts()))\n",
    "print('Number of unique parent categories:',len(train.parent_category_name.value_counts()))\n",
    "print('Number of unique categories:',len(train.category_name.value_counts()))\n",
    "print('Number of unique descriptions:',len(train.description.value_counts()))\n",
    "print('Number of unique titles:',len(train.title.value_counts()))\n",
    "print('Number of unique param_1:',len(train.param_1.value_counts()))\n",
    "print('Number of unique param_2:',len(train.param_2.value_counts()))\n",
    "print('Number of unique param_3',len(train.param_3.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description and title have too many unique values,\n",
    "# Therefore this method would take too long.\n",
    "cyr_vars = ['region','city','parent_category_name','category_name',\n",
    "           'param_1','param_2','param_3']\n",
    "\n",
    "for var in cyr_vars:\n",
    "    for dataset in [train,test]:\n",
    "        # Get unique cyrilic vlaues\n",
    "        cyrilic_unique = np.unique(dataset[var].fillna('Blank')).tolist()\n",
    "        # Get unique latin translations\n",
    "        latin_unique = [cyrtranslit.to_latin(string,'ru') for string in cyrilic_unique]\n",
    "\n",
    "        # Put lists in a dictionary\n",
    "        trans_dict = {}\n",
    "        for cyr, lat in zip(cyrilic_unique,latin_unique):\n",
    "            trans_dict[cyr]=lat\n",
    "\n",
    "        # Create a translated list\n",
    "        en_list = []\n",
    "        for key in dataset[var].fillna('Blank'):\n",
    "            en_list.append(trans_dict[key])\n",
    "\n",
    "        # Add english list as column\n",
    "        dataset[str(var)+'_en'] = en_list\n",
    "        dataset.drop(var,axis=1,inplace=True)\n",
    "\n",
    "del cyrilic_unique,latin_unique,trans_dict,en_list,dataset,cyr_vars,var,cyr,lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_en</th>\n",
       "      <th>city_en</th>\n",
       "      <th>parent_category_name_en</th>\n",
       "      <th>category_name_en</th>\n",
       "      <th>param_1_en</th>\n",
       "      <th>param_2_en</th>\n",
       "      <th>param_3_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sverdlovskaja oblast'</td>\n",
       "      <td>Ekaterinburg</td>\n",
       "      <td>Lichnye veszi</td>\n",
       "      <td>Tovary dlja detej i igrushki</td>\n",
       "      <td>Postel'nye prinadlezhnosti</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samarskaja oblast'</td>\n",
       "      <td>Samara</td>\n",
       "      <td>Dlja doma i dachi</td>\n",
       "      <td>Mebel' i inter'er</td>\n",
       "      <td>Drugoe</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rostovskaja oblast'</td>\n",
       "      <td>Rostov-na-Donu</td>\n",
       "      <td>Bytovaja ehlektronika</td>\n",
       "      <td>Audio i video</td>\n",
       "      <td>Video, DVD i Blu-ray pleery</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region_en         city_en parent_category_name_en  \\\n",
       "0  Sverdlovskaja oblast'    Ekaterinburg           Lichnye veszi   \n",
       "1     Samarskaja oblast'          Samara       Dlja doma i dachi   \n",
       "2    Rostovskaja oblast'  Rostov-na-Donu   Bytovaja ehlektronika   \n",
       "\n",
       "               category_name_en                   param_1_en param_2_en  \\\n",
       "0  Tovary dlja detej i igrushki   Postel'nye prinadlezhnosti      Blank   \n",
       "1             Mebel' i inter'er                       Drugoe      Blank   \n",
       "2                 Audio i video  Video, DVD i Blu-ray pleery      Blank   \n",
       "\n",
       "  param_3_en  \n",
       "0      Blank  \n",
       "1      Blank  \n",
       "2      Blank  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_en</th>\n",
       "      <th>city_en</th>\n",
       "      <th>parent_category_name_en</th>\n",
       "      <th>category_name_en</th>\n",
       "      <th>param_1_en</th>\n",
       "      <th>param_2_en</th>\n",
       "      <th>param_3_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volgogradskaja oblast'</td>\n",
       "      <td>Volgograd</td>\n",
       "      <td>Lichnye veszi</td>\n",
       "      <td>Detskaja odezhda i obuv'</td>\n",
       "      <td>Dlja mal'chikov</td>\n",
       "      <td>Obuv'</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sverdlovskaja oblast'</td>\n",
       "      <td>Nizhnjaja Tura</td>\n",
       "      <td>Hobbi i otdyh</td>\n",
       "      <td>Velosipedy</td>\n",
       "      <td>Dorozhnye</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novosibirskaja oblast'</td>\n",
       "      <td>Berdsk</td>\n",
       "      <td>Bytovaja ehlektronika</td>\n",
       "      <td>Audio i video</td>\n",
       "      <td>Televizory i proektory</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region_en         city_en parent_category_name_en  \\\n",
       "0  Volgogradskaja oblast'       Volgograd           Lichnye veszi   \n",
       "1   Sverdlovskaja oblast'  Nizhnjaja Tura           Hobbi i otdyh   \n",
       "2  Novosibirskaja oblast'          Berdsk   Bytovaja ehlektronika   \n",
       "\n",
       "           category_name_en              param_1_en param_2_en param_3_en  \n",
       "0  Detskaja odezhda i obuv'         Dlja mal'chikov      Obuv'         25  \n",
       "1                Velosipedy               Dorozhnye      Blank      Blank  \n",
       "2             Audio i video  Televizory i proektory      Blank      Blank  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See latin translations\n",
    "print('Train Data:')\n",
    "display(train.iloc[:3,-7:])\n",
    "print(\"\")\n",
    "print('Test Data:')\n",
    "display(test.iloc[:3,-7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies\n",
    "### City Features\n",
    "- The number of unique cities in train is too large (1700) and leads to `MemoryError`. Let's pick a subset of those cities. The most useful might be those which appear in both train and test. Cities appearing only in train won't help predict anything in test that regards the city variable, and listings from cities which appear only in test can't be predicted with train information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comon cities: 1625\n",
      "N Listings in both sets from unique common cities: 2011447\n"
     ]
    }
   ],
   "source": [
    "# Find which cities are in both train and test sets\n",
    "test_unique = test.city_en.unique()\n",
    "train_unique = train.city_en.unique()\n",
    "\n",
    "common = [city for city in train_unique if city in test_unique]\n",
    "del test_unique,train_unique\n",
    "\n",
    "print('Unique comon cities:',len(common))\n",
    "\n",
    "# Create features from the most popular cities in common set\n",
    "\n",
    "# Get common cities in train and test\n",
    "train_common = train[train.city_en.apply(lambda x: x in common)].city_en\n",
    "test_common = test[test.city_en.apply(lambda x: x in common)].city_en\n",
    "\n",
    "# Merge sets of common cities\n",
    "traintest_common = train_common.append(test_common)\n",
    "print('N Listings in both sets from unique common cities:',traintest_common.shape[0])\n",
    "\n",
    "# Count values among merged set\n",
    "top_common = traintest_common.value_counts()[:150].keys().tolist()\n",
    "del common,train_common,test_common,traintest_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1625 is still too many cities for feature purposes. Let's find which of those are the most popular among both sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll store our machine learning features\n",
    "train_features = pd.DataFrame(index=train.index)\n",
    "#test_features = pd.DataFrame(index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in top_common:\n",
    "    train_features[str(city)] = np.where(train.city_en == city,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 150)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection of Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features above 0.01 Variance: 29\n",
      "\n",
      "Features Selected:\n",
      " ['Ekaterinburg', 'Krasnodar', 'Novosibirsk', 'Nizhnij Novgorod', 'Rostov-na-Donu', 'CHeljabinsk', \"Kazan'\", \"Perm'\", 'Samara', 'Ufa', 'Omsk', 'Krasnojarsk', 'Voronezh', 'Volgograd', 'Saratov', \"Tjumen'\", 'Kaliningrad', 'Barnaul', \"JAroslavl'\", 'Irkutsk', 'Orenburg', 'Izhevsk', 'Sochi', \"Tol'jatti\", 'Kemerovo', 'Belgorod', 'Tula', 'Naberezhnye CHelny', \"Stavropol'\"]\n"
     ]
    }
   ],
   "source": [
    "selector = feature_selection.VarianceThreshold(0.01)\n",
    "print('Number of Features above 0.01 Variance:',selector.fit_transform(train_features).shape[1])\n",
    "var_f = train_features.columns[selector.get_support()].tolist()\n",
    "print('\\nFeatures Selected:\\n',var_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variance Threshold doesn't take into account the target variable. At 0.01 variance, it removes all but 29 of cities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "- Since we know 29 variables are above 0.01 variance threshold, I'll use that number to compare with other feature selection techniques. Here, the top 29 absolute correlation cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 29 absolute correlation cities:\n",
      " ['Krasnojarsk', 'Ekaterinburg', 'Novosibirsk', \"Tjumen'\", 'Rostov-na-Donu', 'Buzuluk', 'Kropotkin', 'Sochi', 'Omsk', 'Belorechensk', 'Labinsk', 'Armavir', 'Nizhnekamsk', \"Tol'jatti\", 'Slavjansk-na-Kubani', 'Georgievsk', \"JAroslavl'\", 'Novorossijsk', 'Borisoglebsk', 'Orenburg', 'Tihoreck', 'Kamensk-SHahtinskij', 'Sterlitamak', \"Oktjabr'skij\", 'Millerovo', 'Balakovo', 'Nevinnomyssk', 'Minusinsk', 'Liski']\n"
     ]
    }
   ],
   "source": [
    "# Top absolute correlation cities\n",
    "cor_f = np.absolute(train_features.corrwith(train.deal_probability)).sort_values(ascending=False)[:29].keys().tolist()\n",
    "print('Top 29 absolute correlation cities:\\n',cor_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F Test Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Best Features Selected by F Regression:\n",
      " ['Ekaterinburg', 'Novosibirsk', 'Rostov-na-Donu', 'Omsk', 'Krasnojarsk', \"Tjumen'\", \"JAroslavl'\", 'Orenburg', 'Sochi', \"Tol'jatti\", 'Novorossijsk', 'Sterlitamak', 'Nizhnekamsk', 'Balakovo', 'Armavir', 'Nevinnomyssk', \"Oktjabr'skij\", 'Buzuluk', 'Slavjansk-na-Kubani', 'Kropotkin', 'Belorechensk', 'Kamensk-SHahtinskij', 'Georgievsk', 'Minusinsk', 'Tihoreck', 'Borisoglebsk', 'Labinsk', 'Liski', 'Millerovo']\n"
     ]
    }
   ],
   "source": [
    "f_reg = feature_selection.f_regression\n",
    "selector = feature_selection.SelectKBest(f_reg, k=29)\n",
    "selector.fit(train_features,train.deal_probability).get_support()\n",
    "kbest_f = train_features.columns[selector.get_support()].tolist()\n",
    "print('29 Best Features Selected by F Regression:\\n',kbest_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Feature Selection Techniques Against a RidgeRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train', 2177612018),\n",
       " ('train_features', 1804108904),\n",
       " ('top_common', 1264),\n",
       " ('cor_f', 296),\n",
       " ('features', 296),\n",
       " ('kbest_f', 296),\n",
       " ('var_f', 296),\n",
       " ('color', 176),\n",
       " ('f_reg', 136),\n",
       " ('city', 83),\n",
       " ('ensemble', 80),\n",
       " ('feature_selection', 80),\n",
       " ('lgb', 80),\n",
       " ('linear_model', 80),\n",
       " ('metrics', 80),\n",
       " ('model_selection', 80),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('plt', 80),\n",
       " ('preprocessing', 80),\n",
       " ('sns', 80),\n",
       " ('lasso_f', 64),\n",
       " ('estimator', 56),\n",
       " ('selector', 56),\n",
       " ('key', 54)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features: Param_1, 2 & 3\n",
    "- Features from these are challenging because some values repeat in more than one of these variables. Therefore when creating dummies, column names overlap. Adding prefixes helps but some values exist only in train or test set, therefore each set ends with a different number of features. The solution is to gather a custom list of values to create features from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features: Region, Parent Category, Category\n",
    "- These can be done without as much juggling as `city` or `param_x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Categorical variables for dummies, except city.\n",
    "cat_vars = train.columns[-7:].drop('city_en')\n",
    "\n",
    "# Get dummies in both train and test\n",
    "for var in cat_vars:\n",
    "    for dataset in [train,test]:\n",
    "        dummies = pd.get_dummies(dataset[var],prefix=var)\n",
    "        if len(dataset) == len(train):\n",
    "            train_features = train_features.join(dummies)\n",
    "        elif len(dataset) == len(test):\n",
    "            test_features = test_features.join(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train[['price_fill','item_seq_number','activation_date''image_top_1','deal_probability']].copy()\n",
    "test_features = test[['price_fill','item_seq_number','activation_date''image_top_1']].copy()\n",
    "\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "for col in cat_vars:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train[col].values.astype('str')) + list(test[col].values.astype('str')))\n",
    "    train_features[col] = lbl.transform(list(train[col].values.astype('str')))\n",
    "    test_features[col] = lbl.transform(list(test[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"deal_probability\"].values\n",
    "\n",
    "# Label encode the categorical variables #\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "for col in cat_vars:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))\n",
    "\n",
    "cols_to_drop = [\"item_id\", \"user_id\", \"title\", \"description\", \"activation_date\", \"image\"]\n",
    "train_X = train_df.drop(cols_to_drop + [\"region_en\", \"parent_category_name_en\", \"category_name_en\", \"price_new\", \"deal_probability\"], axis=1)\n",
    "test_X = test_df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=20, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more Features\n",
    "\n",
    "- (Feature) has description\n",
    "- (Feature) has photo\n",
    "- (Feature) has param 1,2,3\n",
    "- (Feature) has price\n",
    "- (Feature) word count in title, description,\n",
    "- (Feature) population of region\n",
    "- (Feature) string value is unique. title, description, param1, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New variable on weekday #\n",
    "#train[\"activation_weekday\"] = train[\"activation_date\"].dt.weekday\n",
    "#test[\"activation_weekday\"] = test[\"activation_date\"].dt.weekday\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
