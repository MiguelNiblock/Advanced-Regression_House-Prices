{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "I already did a first iteration of this `TFIDF PLSR` procedure in a previous notebook. Now Im simply gonna compare results with different approaches, namely:\n",
    "- Using Stopwords in russian.\n",
    "- Using NGrams.\n",
    "- Not transforming terms to Lowercase.\n",
    "- Decomposing more CSR columns.\n",
    "- Training $PLSR$ with larger samples of the CSR matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import cyrtranslit\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection, ensemble, linear_model, cross_decomposition, feature_extraction, decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../../train.pkl',compression='zip')\n",
    "\n",
    "test = pd.read_pickle('../../test.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Vectorize Titles with Russian StopWords\n",
    "**Summary**\n",
    "\n",
    "- $R^2$ score is lower but pretty close to the one without russian stopwords.\n",
    "- $RMSE$ is also slightly worse. It's still worth getting the score on the full data.\n",
    "- Score on all train data was also slightly lower. However, a random iteration gave a higher one. This score remained the most constant. It is inconclusive so far whether stopwords made any difference in titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of russian stopwords from NLTK\n",
    "nltk.corpus.stopwords.words('russian')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_stop = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=True,\n",
    "    #min_df=0.00003,\n",
    "    max_features=8600\n",
    ")\n",
    "# Fitting on train and test as merged lists\n",
    "vec.fit(train['title'].values.tolist() + test['title'].values.tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train titles. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(train),size=int(1e5))\n",
    "\n",
    "# (FIRST) Select those indices from the Sparse matrix and then turn into an array.\n",
    "sample = counts[index].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26151920926493344"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More components didn't offer a significant gain \n",
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "\n",
    "# Fit undersampled array against the same indices for the target.\n",
    "reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "\n",
    "# PLSR score reducing random sample into n components.\n",
    "reduce.score(sample,train.iloc[index].deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050281080394525314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reduce.predict(sample)\n",
    "\n",
    "metrics.mean_squared_error(train.iloc[index].deal_probability,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce all CSR values in batches\n",
    "reduced = pd.DataFrame()\n",
    "lower = 0\n",
    "for idx in np.arange(0,int(len(train)*1.1),int(1.1e5)):\n",
    "    if idx > len(train):\n",
    "        idx = len(train)\n",
    "    upper = idx\n",
    "    if upper > lower:\n",
    "        #print(lower,upper)\n",
    "        sample = counts[lower:upper].toarray()\n",
    "        sample = reduce.transform(sample)\n",
    "        reduced = reduced.append(pd.DataFrame(sample))\n",
    "        lower = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14190194473492246"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(reduced,train.deal_probability)\n",
    "linear.score(reduced,train.deal_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stopwords for Descriptions\n",
    "**Summary**\n",
    "\n",
    "- In the grand scheme of things, using stopwords makes descriptions almost as useful as titles predictively.\n",
    "- For some reason, overfitting is less worse with descriptions than with titles. (0.19 vs 0.13 descriptions) (0.26 vs 0.14 titles)\n",
    "- Perhaps this is because there are more stopwords in descriptions, so they benefit more from removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=True,\n",
    "    #min_df=0.00003,\n",
    "    max_features=4500\n",
    ")\n",
    "# Fitting on train and test as merged lists\n",
    "vec.fit(train['description'].astype(str).tolist() + test['description'].astype(str).tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['description'].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(train),size=int(1e5))\n",
    "\n",
    "# (FIRST) Select those indices from the Sparse matrix and then turn into an array.\n",
    "sample = counts[index].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19728699139064343"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More components didn't offer a significant gain \n",
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "\n",
    "# Fit undersampled array against the same indices for the target.\n",
    "reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "\n",
    "# PLSR score reducing random sample to n components.\n",
    "reduce.score(sample,train.iloc[index].deal_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That's a higher score than our descriptions without stopwords. `0.1954`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce all CSR values in batches\n",
    "reduced = pd.DataFrame()\n",
    "lower = 0\n",
    "for i,idx in enumerate(np.arange(0,int(len(train)*1.1),int(1.1e5))):\n",
    "    if idx > len(train):\n",
    "        idx = len(train)\n",
    "    upper = idx\n",
    "    if upper > lower:\n",
    "        #print(lower,upper)\n",
    "        sample = counts[lower:upper].toarray()\n",
    "        sample = reduce.transform(sample)\n",
    "        reduced = reduced.append(pd.DataFrame(sample))\n",
    "        lower = idx\n",
    "    else:\n",
    "        lower = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13796255999177576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(reduced,train.deal_probability)\n",
    "linear.score(reduced,train.deal_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# NGram Ranges on Titles\n",
    "**Summary**\n",
    "\n",
    "- (2,2) and (3,3) performed incredibly poorly. Those examples are deleted.\n",
    "- (1,2) perform significantly better than (2,2). Brings scores almost at par with unigrams, but still slightly below.\n",
    "- That's because (1,2) allows unigrams and bigrams to compete in frequency. Only bigrams which appear more frequently than unigrams would make the cut into the max_features used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    #stop_words=ru_stop,\n",
    "    lowercase=True,\n",
    "    max_features=8600,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "# Fitting on train and test as merged lists\n",
    "vec.fit(train['title'].values.tolist() + test['title'].values.tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(train),size=int(1e5))\n",
    "\n",
    "# (FIRST) Select those indices from the Sparse matrix and then turn into an array.\n",
    "sample = counts[index].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25612322051624004"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More components didn't offer a significant gain \n",
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "\n",
    "# Fit undersampled array against the same indices for the target.\n",
    "reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "\n",
    "# PLSR score reducing random sample to n components.\n",
    "reduce.score(sample,train.iloc[index].deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce all CSR values in batches\n",
    "reduced = pd.DataFrame()\n",
    "lower = 0\n",
    "for i,idx in enumerate(np.arange(0,int(len(train)*1.1),int(1.1e5))):\n",
    "    if idx > len(train):\n",
    "        idx = len(train)\n",
    "    upper = idx\n",
    "    if upper > lower:\n",
    "        #print(lower,upper)\n",
    "        sample = counts[lower:upper].toarray()\n",
    "        sample = reduce.transform(sample)\n",
    "        reduced = reduced.append(pd.DataFrame(sample))\n",
    "        lower = idx\n",
    "    else:\n",
    "        lower = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14216173687810452"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(reduced,train.deal_probability)\n",
    "linear.score(reduced,train.deal_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## NGram Ranges on Descriptions\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- Without stopwords, got `0.1945` on PLSR sample and `0.1333` on full train.\n",
    "- With stopwords, got `0.1922` on PLSR sample and `0.1360` on full train. Again, stopwords improved full score on descriptions only.\n",
    "- However, the highest score for descriptions was in the previous section without NGram Ranges. (`0.1379`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=True,\n",
    "    max_features=4500,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "# Fitting on train and test as merged lists\n",
    "vec.fit(train['description'].astype(str).tolist() + test['description'].astype(str).tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['description'].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(train),size=int(1e5))\n",
    "\n",
    "# (FIRST) Select those indices from the Sparse matrix and then turn into an array.\n",
    "sample = counts[index].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19229064958193207"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More components didn't offer a significant gain \n",
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "\n",
    "# Fit undersampled array against the same indices for the target.\n",
    "reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "\n",
    "# PLSR score reducing random sample to n components.\n",
    "reduce.score(sample,train.iloc[index].deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce all CSR values in batches\n",
    "reduced = pd.DataFrame()\n",
    "lower = 0\n",
    "for i,idx in enumerate(np.arange(0,int(len(train)*1.1),int(1.1e5))):\n",
    "    if idx > len(train):\n",
    "        idx = len(train)\n",
    "    upper = idx\n",
    "    if upper > lower:\n",
    "        #print(lower,upper)\n",
    "        sample = counts[lower:upper].toarray()\n",
    "        sample = reduce.transform(sample)\n",
    "        reduced = reduced.append(pd.DataFrame(sample))\n",
    "        lower = idx\n",
    "    else:\n",
    "        lower = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13605336534332912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(reduced,train.deal_probability)\n",
    "linear.score(reduced,train.deal_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Lowercase on Titles\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- Setting lowercase to False for the first time. Maybe ads with Upper Case have more deal probability.\n",
    "- Score on PLSR sample was `0.2582`, slightly below the `0.266x` benchmark.\n",
    "- On the full train, 0.1356, slightly below the 0.1379 benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    #stop_words=ru_stop,\n",
    "    lowercase=False,\n",
    "    max_features=8600,\n",
    "    #ngram_range=(1,2)\n",
    ")\n",
    "# Fitting on train and test as merged lists\n",
    "vec.fit(train['title'].values.tolist() + test['title'].values.tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(train),size=int(1e5))\n",
    "\n",
    "# (FIRST) Select those indices from the Sparse matrix and then turn into an array.\n",
    "sample = counts[index].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2582151950790056"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More components didn't offer a significant gain \n",
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "\n",
    "# Fit undersampled array against the same indices for the target.\n",
    "reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "\n",
    "# PLSR score reducing random sample to n components.\n",
    "reduce.score(sample,train.iloc[index].deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce all CSR values in batches\n",
    "reduced = pd.DataFrame()\n",
    "lower = 0\n",
    "for i,idx in enumerate(np.arange(0,int(len(train)*1.1),int(1.1e5))):\n",
    "    if idx > len(train):\n",
    "        idx = len(train)\n",
    "    upper = idx\n",
    "    if upper > lower:\n",
    "        #print(lower,upper)\n",
    "        sample = counts[lower:upper].toarray()\n",
    "        sample = reduce.transform(sample)\n",
    "        reduced = reduced.append(pd.DataFrame(sample))\n",
    "        lower = idx\n",
    "    else:\n",
    "        lower = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13565958748292106"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(reduced,train.deal_probability)\n",
    "linear.score(reduced,train.deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13729185, 0.13308195, 0.13636996, 0.13581638])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(cv=4,\n",
    "                                estimator=linear,\n",
    "                                X=reduced,\n",
    "                                y=train.deal_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Observations\n",
    "- All parameters that increase the number of total features tend to produce lower scores. Examples of this are: `lowercase=False`,`ngram_range=(1,2)`. On the other hand, `stopwords` increased the score on descriptions, and it happens to produce less features naturally.\n",
    "- Producing more features to represent the same data has the effect of requiring more of those features retained, in order for PLSR to have more informational value at the start. Changes that produce more features from the same data would increase specificity, but that specificity requires more processing, and my RAM memory forces me to cap the number of features retained to around 8000 for titles and 4500 for descriptions.\n",
    "- Another factor at play is I've been defining the feature filtering with `max_features` and not `min_df` anymore. max_features only keeps those terms which have the most frequency. `min_df` filters terms that don't appear frequently enough. In a sense, `min_df` removes some meaningless terms, while `max_df` removes noisy (and meaningless) terms as well, because they appear too often they might mean nothing as well. I should combine the use of these three parameters as well as all the previous.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Special Combos\n",
    ">If I want to reap the rewards of some specificity (by using lowercase or ngrams) I should first **make memory space.**\n",
    "\n",
    "- With 100k datapoints, I can only load 8000~ features into PLSR at once for titles, and 4500~ for descriptions. Therefore I should filter some terms out with `min/max_df` and see if then adding specificity improves scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=False,\n",
    "    max_features=8600,\n",
    "    ngram_range=(1,2),\n",
    "    min_df=0.000045\n",
    ")\n",
    "# Fitting on train and test as merged lists\n",
    "vec.fit(train['title'].values.tolist() + test['title'].values.tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering terms**\n",
    "\n",
    "- Started with only `stopwords` and `min_df` and got 6237 features. That leaves good room before the 8600 cap.\n",
    "- Then enabling `lowercase=False` gave 6616 total features. That means around 400 features are the same terms in uppercase. (More Specificity)\n",
    "- Surely, enabling the `ngram_range=(1,2)` at this point filled the rest of our cap at 8600 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train titles. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(train),size=int(1e5))\n",
    "\n",
    "# (FIRST) Select those indices from the Sparse matrix and then turn into an array.\n",
    "sample = counts[index].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2453587440424907"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More components didn't offer a significant gain \n",
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "\n",
    "# Fit undersampled array against the same indices for the target.\n",
    "reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "\n",
    "# PLSR score reducing random sample to N components.\n",
    "reduce.score(sample,train.iloc[index].deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce all CSR values in batches\n",
    "reduced = pd.DataFrame()\n",
    "lower = 0\n",
    "for i,idx in enumerate(np.arange(0,int(len(train)*1.1),int(1.1e5))):\n",
    "    if idx > len(train):\n",
    "        idx = len(train)\n",
    "    upper = idx\n",
    "    if upper > lower:\n",
    "        #print(lower,upper)\n",
    "        sample = counts[lower:upper].toarray()\n",
    "        sample = reduce.transform(sample)\n",
    "        reduced = reduced.append(pd.DataFrame(sample))\n",
    "        lower = idx\n",
    "    else:\n",
    "        lower = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13463212179427675"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(reduced,train.deal_probability)\n",
    "linear.score(reduced,train.deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13529843, 0.13176643, 0.1363894 , 0.1349529 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(cv=4,\n",
    "                                estimator=linear,\n",
    "                                X=reduced,\n",
    "                                y=train.deal_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That didn't produce a higher train result. We should find out where is the primary information value in this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Greatest Information Value\n",
    "\n",
    ">To know if more specificity adds predictive power, I must be able to process more features in order to assess that gain. To process more features, I here do several rounds of PLSR to handle significantly larger CSR matrices. \n",
    "\n",
    "**Summary**\n",
    "\n",
    "- This approach **increased scores** without the use of `lowercase=False` or `NGrams`, which suggests **there is an information value in processing more unigram counts from the CSR.**\n",
    "- In a later step, I will allow the extraction of `NGrams` and `lowercase=False` features in addition to the ones extracted in this step, and evaluate for any score increases.\n",
    "- Meanwhile to **combat overfitting**, PLSR is being trained with larger samples of the CSR(400k) which is a four-fold increase from the 100k size used previously. Now the training size is about a quarter of the whole train data(1.5Million).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29333\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    #lowercase=False,\n",
    "    #max_features=8600,\n",
    "    #ngram_range=(1,2),\n",
    "    min_df=0.000005,\n",
    "    #max_df=0.0005\n",
    ")\n",
    "# Fitting on train and test as merged lists\n",
    "vec.fit(train['title'].values.tolist() + test['title'].values.tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering Features**\n",
    "\n",
    "- I'll leave around 30k features. Then create separate PLSR decompositions for separate columnar ranges.\n",
    "- I'll also increase the sample size to train PLSR and handle less features at once to ensure there's enough RAM memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train titles. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 29333)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "- The counts CSR matrix is now larger than I've ever done PLSR with.\n",
    "- Sample size will increase to 400k. And will process 2k, maybe 3k features at once.\n",
    "- The random index for each PLSR training sample will vary for each batch of features, because it is only used in the `fit` step on PLSR. But the indexes for transforming columns and rows in batches will follow a strict order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for feature range: 0.026233317577446624\n",
      "Indexes: 0 310000 Columns: 0 2000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 0 2000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 0 2000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 0 2000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 0 2000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 5) \n",
      "\n",
      "Score for feature range: 0.013189517053110555\n",
      "Indexes: 0 310000 Columns: 2000 4000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 2000 4000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 2000 4000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 2000 4000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 2000 4000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 10) \n",
      "\n",
      "Score for feature range: 0.01896583078454539\n",
      "Indexes: 0 310000 Columns: 4000 6000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 4000 6000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 4000 6000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 4000 6000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 4000 6000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 15) \n",
      "\n",
      "Score for feature range: 0.016993942670614492\n",
      "Indexes: 0 310000 Columns: 6000 8000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 6000 8000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 6000 8000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 6000 8000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 6000 8000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 20) \n",
      "\n",
      "Score for feature range: 0.017195571021365597\n",
      "Indexes: 0 310000 Columns: 8000 10000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 8000 10000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 8000 10000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 8000 10000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 8000 10000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 25) \n",
      "\n",
      "Score for feature range: 0.036318038357224136\n",
      "Indexes: 0 310000 Columns: 10000 12000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 10000 12000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 10000 12000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 10000 12000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 10000 12000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 30) \n",
      "\n",
      "Score for feature range: 0.03663186154546283\n",
      "Indexes: 0 310000 Columns: 12000 14000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 12000 14000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 12000 14000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 12000 14000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 12000 14000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 35) \n",
      "\n",
      "Score for feature range: 0.02365398661792406\n",
      "Indexes: 0 310000 Columns: 14000 16000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 14000 16000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 14000 16000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 14000 16000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 14000 16000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 40) \n",
      "\n",
      "Score for feature range: 0.034014032371067926\n",
      "Indexes: 0 310000 Columns: 16000 18000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 16000 18000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 16000 18000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 16000 18000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 16000 18000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 45) \n",
      "\n",
      "Score for feature range: 0.030982576806122934\n",
      "Indexes: 0 310000 Columns: 18000 20000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 18000 20000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 18000 20000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 18000 20000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 18000 20000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 50) \n",
      "\n",
      "Score for feature range: 0.03439038781135062\n",
      "Indexes: 0 310000 Columns: 20000 22000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 20000 22000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 20000 22000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 20000 22000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 20000 22000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 55) \n",
      "\n",
      "Score for feature range: 0.02888382576804338\n",
      "Indexes: 0 310000 Columns: 22000 24000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 22000 24000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 22000 24000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 22000 24000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 22000 24000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 60) \n",
      "\n",
      "Score for feature range: 0.029568393346116717\n",
      "Indexes: 0 310000 Columns: 24000 26000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 24000 26000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 24000 26000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 24000 26000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 24000 26000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 65) \n",
      "\n",
      "Score for feature range: 0.03181165965277477\n",
      "Indexes: 0 310000 Columns: 26000 28000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 310000 620000 Columns: 26000 28000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 620000 930000 Columns: 26000 28000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 930000 1240000 Columns: 26000 28000\n",
      "Sample shape: (310000, 2000)\n",
      "Indexes: 1240000 1503424 Columns: 26000 28000\n",
      "Sample shape: (263424, 2000)\n",
      "(1503424, 70) \n",
      "\n",
      "Score for feature range: 0.01867721235286357\n",
      "Indexes: 0 310000 Columns: 28000 29333\n",
      "Sample shape: (310000, 1333)\n",
      "Indexes: 310000 620000 Columns: 28000 29333\n",
      "Sample shape: (310000, 1333)\n",
      "Indexes: 620000 930000 Columns: 28000 29333\n",
      "Sample shape: (310000, 1333)\n",
      "Indexes: 930000 1240000 Columns: 28000 29333\n",
      "Sample shape: (310000, 1333)\n",
      "Indexes: 1240000 1503424 Columns: 28000 29333\n",
      "Sample shape: (263424, 1333)\n",
      "(1503424, 75) \n",
      "\n",
      "956.2004759311676\n"
     ]
    }
   ],
   "source": [
    "# Reduce all CSR values in batches\n",
    "t = time.time()\n",
    "reduced = pd.DataFrame(index=train.index)\n",
    "low_col = 0\n",
    "# Start iteration with columns\n",
    "for col in np.arange(0,int(counts.shape[1]*1.05),2000):\n",
    "    # Limiting the edge case of the last values\n",
    "    if col > counts.shape[1]:\n",
    "        col = counts.shape[1]\n",
    "    up_col = col\n",
    "    \n",
    "    if up_col > low_col:\n",
    "        # Train PLSR on a large sample of those columns from CSR\n",
    "        index = np.random.choice(len(train),size=int(4e5))\n",
    "        sample = counts[index,low_col:up_col].toarray()\n",
    "        reduce = cross_decomposition.PLSRegression(n_components=5)\n",
    "        reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "        print('Score for feature range:',reduce.score(sample,train.iloc[index].deal_probability))\n",
    "        \n",
    "        # Nested indexes iteration\n",
    "        components = pd.DataFrame()\n",
    "        low_idx = 0\n",
    "        for idx in np.arange(0,int(len(train)*1.1),int(3.1e5)):\n",
    "            # Limiting the edge case of the last values\n",
    "            if idx > len(train):\n",
    "                idx = len(train)\n",
    "            up_idx = idx\n",
    "\n",
    "            if up_idx > low_idx:\n",
    "                print('Indexes:',low_idx,up_idx,'Columns:',low_col,up_col)\n",
    "                sample = counts[low_idx:up_idx,low_col:up_col].toarray()\n",
    "                print('Sample shape:',sample.shape)\n",
    "                sample = reduce.transform(sample)\n",
    "                components = components.append(pd.DataFrame(sample))\n",
    "                low_idx = idx\n",
    "        components.reset_index(drop=True,inplace=True)\n",
    "        components.columns = ['col_{}-{}_{}'.format(low_col,up_col,i) for i in range(0,5)]\n",
    "        reduced = reduced.join(components)\n",
    "        print(reduced.shape,'\\n')\n",
    "        low_col = col\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 75)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced.to_pickle('train_nlp_features.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funny remark**\n",
    "\n",
    "- I really sweated for this 3% increase, lol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16947041244877115"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(reduced,train.deal_probability)\n",
    "linear.score(reduced,train.deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17082166, 0.16651347, 0.16958629, 0.17033808])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(cv=4,\n",
    "                                estimator=linear,\n",
    "                                X=reduced,\n",
    "                                y=train.deal_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05602679, 0.0562293 , 0.05612842, 0.05636757])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = metrics.make_scorer(metrics.mean_squared_error)\n",
    "model_selection.cross_val_score(cv=4,\n",
    "                                estimator=linear,\n",
    "                                X=reduced,\n",
    "                                y=train.deal_probability,\n",
    "                                scoring=rmse\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e59304916793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(20,14))\n",
    "correlation=reduced.corr()\n",
    "sns.heatmap(correlation)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
