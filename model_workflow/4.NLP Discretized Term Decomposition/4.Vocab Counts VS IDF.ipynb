{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import cyrtranslit\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection, ensemble, linear_model, cross_decomposition, feature_extraction, decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../../train.pkl',compression='zip')\n",
    "\n",
    "test = pd.read_pickle('../../test.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_stop = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('../3.NLP StopWords NGrams/train_nlp_features7.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_0 = train[train.deal_probability==0].index.tolist()\n",
    "i_low = train[(train.deal_probability>0)&(train.deal_probability<0.65)].index.tolist()\n",
    "i_up = train[train.deal_probability>=0.65].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary per Discrete Target Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_str = ' '.join(train.loc[i_up,'title'].astype(str).values)\n",
    "lower_str = ' '.join(train.loc[i_low,'title'].astype(str).values)\n",
    "zeroes_str = ' '.join(train.loc[i_0,'title'].astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254857\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.CountVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=False,\n",
    "    #max_features=8600,\n",
    "    #ngram_range=(1,2),\n",
    "    #min_df=0.0005,\n",
    "    #max_df=0.0005,\n",
    "    \n",
    ")\n",
    "vec.fit([zeroes_str,lower_str,upper_str])\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for all titles. They're split into three documents\n",
    "counts = vec.transform([zeroes_str,lower_str,upper_str])\n",
    "del upper_str,lower_str,zeroes_str\n",
    "\n",
    "# Convert CSR into DataFrame and Transpose. Now terms are on the index\n",
    "counts = pd.DataFrame(counts.toarray()).T\n",
    "\n",
    "# Extract terms from vocabulary, sort by index and add to df index\n",
    "vocab = vec.vocabulary_\n",
    "terms = [f for f in vocab]\n",
    "terms = pd.DataFrame(terms)\n",
    "terms['index'] = [vocab[k] for k in vocab] ; del vocab\n",
    "terms.sort_values(by='index',inplace=True)\n",
    "terms = terms[0].values.tolist()\n",
    "counts.index = terms ; del terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an indicator of where the highest frequency is for each term\n",
    "group = []\n",
    "for i in np.arange(len(counts)):\n",
    "    group.append(np.argmax(counts.iloc[i].values))      \n",
    "counts['group'] = group ; del group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ёрочка</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ёршик</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ёта</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ёх</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ёхкомфорчатая</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1  2  group\n",
       "ёрочка         1  0  0      0\n",
       "ёршик          3  0  0      0\n",
       "ёта            1  2  0      1\n",
       "ёх             2  1  1      0\n",
       "ёхкомфорчатая  0  0  1      2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vocab = counts[counts.group == 0].sort_values(by=0,ascending=False).index.tolist()\n",
    "lower_vocab = counts[counts.group == 1].sort_values(by=1,ascending=False).index.tolist()\n",
    "upper_vocab = counts[counts.group == 2].sort_values(by=2,ascending=False).index.tolist()\n",
    "\n",
    "vocabs = [upper_vocab,lower_vocab,zero_vocab]\n",
    "vocabs = pd.DataFrame(vocabs)\n",
    "vocabs = vocabs.T\n",
    "vocabs.columns=['up_voc','low_voc','zero_voc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up_voc</th>\n",
       "      <th>low_voc</th>\n",
       "      <th>zero_voc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Холодильник</td>\n",
       "      <td>м²</td>\n",
       "      <td>Продам</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Грузоперевозки</td>\n",
       "      <td>эт</td>\n",
       "      <td>Платье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ходунки</td>\n",
       "      <td>квартира</td>\n",
       "      <td>Куртка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>трость</td>\n",
       "      <td>сот</td>\n",
       "      <td>платье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Прогулочная</td>\n",
       "      <td>участке</td>\n",
       "      <td>Туфли</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           up_voc   low_voc zero_voc\n",
       "0     Холодильник        м²   Продам\n",
       "1  Грузоперевозки        эт   Платье\n",
       "2         Ходунки  квартира   Куртка\n",
       "3          трость       сот   платье\n",
       "4     Прогулочная   участке    Туфли"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs.to_pickle('vocabs_count.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components for Range Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = pd.read_pickle('vocabs_count.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197377\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=False,\n",
    "    #max_features=8600,\n",
    "    #ngram_range=(1,2),\n",
    "    #min_df=0.0005,\n",
    "    #max_df=0.0005,\n",
    "    vocabulary=vocabs.zero_voc.dropna()\n",
    ")\n",
    "vec.fit(train['title'].astype(str).tolist()+test['title'].astype(str).tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 197377)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts[:,:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trange = i_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR Columns: 0 2000\n",
      "Score for feature range: 0.10420757966339034\n",
      "Score for sampled target range values of feature range: 0.0\n",
      "Aggregate score: [0.09807088 0.09501095 0.09849168 0.09716395]\n",
      "Aggregate score for target range: [1. 1. 1. 1.]\n",
      "Aggregate shape: (1503424, 5) \n",
      "\n",
      "CSR Columns: 2000 4000\n",
      "Score for feature range: 0.021583775305420886\n",
      "Score for sampled target range values of feature range: 0.0\n",
      "Aggregate score: [0.10664897 0.10289611 0.10663752 0.10521264]\n",
      "Aggregate score for target range: [1. 1. 1. 1.]\n",
      "Aggregate shape: (1503424, 10) \n",
      "\n",
      "CSR Columns: 4000 6000\n",
      "Score for feature range: 0.013713907489169785\n",
      "Score for sampled target range values of feature range: 0.0\n",
      "Aggregate score: [0.111016   0.10680108 0.11095778 0.10962193]\n",
      "Aggregate score for target range: [1. 1. 1. 1.]\n",
      "Aggregate shape: (1503424, 15) \n",
      "\n",
      "CSR Columns: 6000 8000\n",
      "Score for feature range: 0.010439228227177577\n",
      "Score for sampled target range values of feature range: 0.0\n",
      "Aggregate score: [0.11371794 0.10957334 0.1137776  0.11230338]\n",
      "Aggregate score for target range: [1. 1. 1. 1.]\n",
      "Aggregate shape: (1503424, 20) \n",
      "\n",
      "CSR Columns: 8000 10000\n",
      "Score for feature range: 0.008814173209378384\n",
      "Score for sampled target range values of feature range: 0.0\n",
      "Aggregate score: [0.11578697 0.11145418 0.11558982 0.11406324]\n",
      "Aggregate score for target range: [1. 1. 1. 1.]\n",
      "Aggregate shape: (1503424, 25) \n",
      "\n",
      "CSR Columns: 10000 12000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-719c212bc56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mup_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_decomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLSRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mreduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         print('Score for feature range:',\n\u001b[1;32m     20\u001b[0m               reduce.score(sample,train.iloc[index].deal_probability))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         X = check_array(X, dtype=np.float64, copy=self.copy,\n\u001b[0;32m--> 252\u001b[0;31m                         ensure_min_samples=2)\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# false positives from overflow in sum method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reduce all CSR values in batches\n",
    "t = time.time()\n",
    "reduced = pd.DataFrame(index=train.index)\n",
    "low_col = 0\n",
    "# Start iteration with columns\n",
    "for col in np.arange(0,int(counts.shape[1]*1.05),2000):\n",
    "    # Limiting the edge case of the last values\n",
    "    if col > counts.shape[1]:\n",
    "        col = counts.shape[1]\n",
    "    up_col = col\n",
    "    \n",
    "    if up_col > low_col:\n",
    "        # Train PLSR on a large sample of those columns from CSR\n",
    "        print('CSR Columns:',low_col,up_col)\n",
    "        index = np.random.choice(len(train),size=int(4e5),replace=False)\n",
    "        sample = counts[index,low_col:up_col].toarray()\n",
    "        reduce = cross_decomposition.PLSRegression(n_components=5)\n",
    "        reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "        print('Score for feature range:',\n",
    "              reduce.score(sample,train.iloc[index].deal_probability))\n",
    "        # Get scores for values of this target range\n",
    "        tindex = np.random.choice(trange,size=int(4e5),replace=False)\n",
    "        tsample = counts[tindex,low_col:up_col].toarray()\n",
    "        print('Score for sampled target range values of feature range:',\n",
    "              reduce.score(tsample,train.iloc[tindex].deal_probability))\n",
    "\n",
    "        # Nested indexes iteration\n",
    "        components = pd.DataFrame()\n",
    "        low_idx = 0\n",
    "        for idx in np.arange(0,int(len(train)*1.1),int(3.1e5)):\n",
    "            # Limiting the edge case of the last values\n",
    "            if idx > len(train):\n",
    "                idx = len(train)\n",
    "            up_idx = idx\n",
    "\n",
    "            if up_idx > low_idx:\n",
    "                #print('Indexes:',low_idx,up_idx,'Columns:',low_col,up_col)\n",
    "                sample = counts[low_idx:up_idx,low_col:up_col].toarray()\n",
    "                #print('Sample shape:',sample.shape)\n",
    "                sample = reduce.transform(sample)\n",
    "                components = components.append(pd.DataFrame(sample))\n",
    "                low_idx = idx\n",
    "        components.reset_index(drop=True,inplace=True)\n",
    "        components.columns = ['col_{}-{}_{}'.format(low_col,up_col,i) for i in range(0,5)]\n",
    "        reduced = reduced.join(components)\n",
    "        print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced,y=train.deal_probability))\n",
    "        # Get scores for values of this target range\n",
    "        print('Aggregate score for target range:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange],y=train.iloc[trange].deal_probability))\n",
    "        print('Aggregate shape:',reduced.shape,'\\n')\n",
    "        low_col = col\n",
    "print('Minutes:',(time.time()-t)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 25)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced.to_pickle('zero_nlp.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced = pd.read_pickle('zero_titles.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.11578697 0.11145418 0.11558982 0.11406324]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange],y=train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Round of Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1142580011411013\n"
     ]
    }
   ],
   "source": [
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "reduce.fit(reduced,train.deal_probability)\n",
    "print(reduce.score(reduced,train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced2 = reduce.transform(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced2 = pd.DataFrame(reduced2,columns=['zero_titles{}'.format(i) for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced2.to_pickle('zero_titles_counts.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced2 = pd.read_pickle('zero_titles_counts.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('../3.NLP StopWords NGrams/train_nlp_features7.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.2119555  0.20694358 0.21112967 0.21182824]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05324741 0.05350178 0.05332047 0.05354871]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(reduced2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.21470814 0.20929417 0.2137655  0.2142187 ]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05306142 0.0533432  0.05314231 0.05338631]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = pd.read_pickle('../1.General Features/train_features.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1789636188430117\n"
     ]
    }
   ],
   "source": [
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "reduce.fit(categorical,train.deal_probability)\n",
    "print(reduce.score(categorical,train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = reduce.transform(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.18077894 0.17705142 0.17877561 0.17916458]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=categorical,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05535398 0.05551838 0.05550731 0.0557679 ]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=categorical,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(pd.DataFrame(categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.22695156 0.22206013 0.22543913 0.22599221]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05223414 0.05248197 0.05235328 0.05258641]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2285475880424031"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.052234**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components for Lower Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = pd.read_pickle('vocabs_count.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41218\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=False,\n",
    "    #max_features=8600,\n",
    "    #ngram_range=(1,2),\n",
    "    #min_df=0.0005,\n",
    "    #max_df=0.0005,\n",
    "    vocabulary=vocabs.low_voc.dropna()\n",
    ")\n",
    "vec.fit(train['title'].astype(str).tolist()+test['title'].astype(str).tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts[:,:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trange = i_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR Columns: 0 2000\n",
      "Score for feature range: 0.07650316555064651\n",
      "Score for sampled target range values of feature range: -0.24625674791380758\n",
      "Aggregate score: [0.06937051 0.06649627 0.06790187 0.06651316]\n",
      "Aggregate score for target range: [0.08610789 0.08497998 0.08968455 0.08481489]\n",
      "Aggregate shape: (1503424, 5) \n",
      "\n",
      "CSR Columns: 2000 4000\n",
      "Score for feature range: 0.009915923153634432\n",
      "Score for sampled target range values of feature range: -0.28970327808166196\n",
      "Aggregate score: [0.07137912 0.06878748 0.06997201 0.06861146]\n",
      "Aggregate score for target range: [0.0899796  0.08861287 0.09308295 0.08837208]\n",
      "Aggregate shape: (1503424, 10) \n",
      "\n",
      "CSR Columns: 4000 6000\n",
      "Score for feature range: 0.00518673630257771\n",
      "Score for sampled target range values of feature range: -0.2787632441319918\n",
      "Aggregate score: [0.07230028 0.06964049 0.07075534 0.06933913]\n",
      "Aggregate score for target range: [0.09122421 0.08976523 0.09410134 0.0895081 ]\n",
      "Aggregate shape: (1503424, 15) \n",
      "\n",
      "CSR Columns: 6000 8000\n",
      "Score for feature range: 0.002947434663934878\n",
      "Score for sampled target range values of feature range: -0.2652245748945159\n",
      "Aggregate score: [0.07269388 0.07008228 0.07121326 0.06982977]\n",
      "Aggregate score for target range: [0.09201766 0.09020002 0.09499128 0.09024611]\n",
      "Aggregate shape: (1503424, 20) \n",
      "\n",
      "CSR Columns: 8000 10000\n",
      "Score for feature range: 0.0031402433167267985\n",
      "Score for sampled target range values of feature range: -0.2675191932960421\n",
      "Aggregate score: [0.07307439 0.07072237 0.07176821 0.07028956]\n",
      "Aggregate score for target range: [0.09259344 0.09102057 0.09598248 0.09098023]\n",
      "Aggregate shape: (1503424, 25) \n",
      "\n",
      "CSR Columns: 10000 12000\n",
      "Score for feature range: 0.001002194335042117\n",
      "Score for sampled target range values of feature range: -0.25990679239723713\n",
      "Aggregate score: [ 7.32183773e-02  7.09609034e-02 -8.29922857e+07  7.05041742e-02]\n",
      "Aggregate score for target range: [ 9.28963935e-02  9.17590985e-02 -8.44281552e+05  9.14585795e-02]\n",
      "Aggregate shape: (1503424, 30) \n",
      "\n",
      "CSR Columns: 12000 14000\n",
      "Score for feature range: 0.0009617060940775302\n",
      "Score for sampled target range values of feature range: -0.2569897381143573\n",
      "Aggregate score: [ 7.35370366e-02  7.12124137e-02 -8.29935918e+07  7.06401391e-02]\n",
      "Aggregate score for target range: [ 9.39404757e-02  9.29133781e-02 -8.72064094e+05  9.20859113e-02]\n",
      "Aggregate shape: (1503424, 35) \n",
      "\n",
      "CSR Columns: 14000 16000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9b8fa4452c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mup_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_decomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLSRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mreduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         print('Score for feature range:',\n\u001b[1;32m     20\u001b[0m               reduce.score(sample,train.iloc[index].deal_probability))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Scale (in place)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_ = (\n\u001b[0;32m--> 274\u001b[0;31m             _center_scale_xy(X, Y, self.scale))\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Residuals (deflated) matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mXk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py\u001b[0m in \u001b[0;36m_center_scale_xy\u001b[0;34m(X, Y, scale)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mx_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mx_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_std\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mx_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m--> 140\u001b[0;31m                keepdims=keepdims)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reduce all CSR values in batches\n",
    "t = time.time()\n",
    "reduced = pd.DataFrame(index=train.index)\n",
    "low_col = 0\n",
    "# Start iteration with columns\n",
    "for col in np.arange(0,int(counts.shape[1]*1.05),2000):\n",
    "    # Limiting the edge case of the last values\n",
    "    if col > counts.shape[1]:\n",
    "        col = counts.shape[1]\n",
    "    up_col = col\n",
    "    \n",
    "    if up_col > low_col:\n",
    "        # Train PLSR on a large sample of those columns from CSR\n",
    "        print('CSR Columns:',low_col,up_col)\n",
    "        index = np.random.choice(len(train),size=int(4e5),replace=False)\n",
    "        sample = counts[index,low_col:up_col].toarray()\n",
    "        reduce = cross_decomposition.PLSRegression(n_components=5)\n",
    "        reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "        print('Score for feature range:',\n",
    "              reduce.score(sample,train.iloc[index].deal_probability))\n",
    "        # Get scores for values of this target range\n",
    "        tindex = np.random.choice(trange,size=int(3e5),replace=False)\n",
    "        tsample = counts[tindex,low_col:up_col].toarray()\n",
    "        print('Score for sampled target range values of feature range:',\n",
    "              reduce.score(tsample,train.iloc[tindex].deal_probability))\n",
    "\n",
    "        # Nested indexes iteration\n",
    "        components = pd.DataFrame()\n",
    "        low_idx = 0\n",
    "        for idx in np.arange(0,int(len(train)*1.1),int(3.1e5)):\n",
    "            # Limiting the edge case of the last values\n",
    "            if idx > len(train):\n",
    "                idx = len(train)\n",
    "            up_idx = idx\n",
    "\n",
    "            if up_idx > low_idx:\n",
    "                #print('Indexes:',low_idx,up_idx,'Columns:',low_col,up_col)\n",
    "                sample = counts[low_idx:up_idx,low_col:up_col].toarray()\n",
    "                #print('Sample shape:',sample.shape)\n",
    "                sample = reduce.transform(sample)\n",
    "                components = components.append(pd.DataFrame(sample))\n",
    "                low_idx = idx\n",
    "        components.reset_index(drop=True,inplace=True)\n",
    "        components.columns = ['col_{}-{}_{}'.format(low_col,up_col,i) for i in range(0,5)]\n",
    "        reduced = reduced.join(components)\n",
    "        print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced,y=train.deal_probability))\n",
    "        # Get scores for values of this target range\n",
    "        print('Aggregate score for target range:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange],y=train.iloc[trange].deal_probability))\n",
    "        print('Aggregate shape:',reduced.shape,'\\n')\n",
    "        low_col = col\n",
    "print('Minutes:',(time.time()-t)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Happened again. The weird thing at component # 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced.to_pickle('lower_titles_count.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced = pd.read_pickle('lower_titles.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.07321292 0.0709281  0.07194869 0.07045962]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[:,:27],y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.09274039 0.09171541 0.09674472 0.09137512]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange,:27],y=train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.0163976  0.01651551 0.01643594 0.01645158]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange,:27],y=train.iloc[trange].deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Round of Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09338076020825548\n"
     ]
    }
   ],
   "source": [
    "reduce = cross_decomposition.PLSRegression(n_components=5)\n",
    "reduce.fit(reduced.iloc[trange,:27],train.iloc[trange].deal_probability)\n",
    "print(reduce.score(reduced.iloc[trange,:27],train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced2 = reduce.transform(reduced.iloc[:,:27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.07072858 0.06840775 0.06857475 0.06789256]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced2,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.0929021  0.09188803 0.09705031 0.0915242 ]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced2[trange],y=train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.01639468 0.01651237 0.01643038 0.01644888]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced2[trange],y=train.iloc[trange].deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(pd.DataFrame(reduced2).corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced2 = pd.DataFrame(reduced2,columns=['lower_titles{}'.format(i) for i in range(0,5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced2.to_pickle('lower_titles_count.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced2 = pd.read_pickle('lower_titles_count.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('../3.NLP StopWords NGrams/train_nlp_features7.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzero_counts = pd.read_pickle('zero_titles_counts.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = pd.read_pickle('../1.General Features/train_features.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1789636188430117\n"
     ]
    }
   ],
   "source": [
    "reduce = cross_decomposition.PLSRegression(n_components=10)\n",
    "reduce.fit(categorical,train.deal_probability)\n",
    "print(reduce.score(categorical,train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = reduce.transform(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical= pd.DataFrame(categorical,columns=['cat_{}'.format(i) for i in np.arange(0,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical.to_pickle('categorical.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical = pd.read_pickle('categorical.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(fzero_counts)\n",
    "features = features.join(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.22695156 0.22206013 0.22543913 0.22599221]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05223414 0.05248197 0.05235328 0.05258641]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(reduced2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.22725435 0.22227478 0.22561828 0.22613892]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05221368 0.05246749 0.05234117 0.05257644]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22850295402904533"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0522136**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components for Upper Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = pd.read_pickle('vocabs_count.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16262\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=False,\n",
    "    #max_features=8600,\n",
    "    #ngram_range=(1,2),\n",
    "    #min_df=0.0005,\n",
    "    #max_df=0.0005,\n",
    "    vocabulary=vocabs.up_voc.dropna()\n",
    ")\n",
    "vec.fit(train['title'].astype(str).tolist()+test['title'].astype(str).tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts[:,:16000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trange = i_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR Columns: 0 2000\n",
      "Score for feature range: 0.05952755753158989\n",
      "Score for sampled target range values of feature range: -94.79326055426434\n",
      "Aggregate score: [0.04677091 0.04372017 0.04630112 0.04688538]\n",
      "Aggregate score for target range: [0.07916429 0.07931283 0.07400564 0.07957582]\n",
      "Aggregate shape: (1503424, 5) \n",
      "\n",
      "CSR Columns: 2000 4000\n",
      "Score for feature range: 0.012719574525752453\n",
      "Score for sampled target range values of feature range: -101.50348290492907\n",
      "Aggregate score: [0.05023597 0.04676691 0.04892466 0.04737093]\n",
      "Aggregate score for target range: [0.080205   0.08011696 0.07415149 0.00775311]\n",
      "Aggregate shape: (1503424, 10) \n",
      "\n",
      "CSR Columns: 4000 6000\n",
      "Score for feature range: 0.009480037934951557\n",
      "Score for sampled target range values of feature range: -101.6418101116684\n",
      "Aggregate score: [ 5.24098376e-02  4.90102876e-02 -4.38353157e+13  4.98052974e-02]\n",
      "Aggregate score for target range: [ 8.40002972e-02  8.57429137e-02 -1.57900995e+14  1.33027929e-02]\n",
      "Aggregate shape: (1503424, 15) \n",
      "\n",
      "CSR Columns: 6000 8000\n",
      "Score for feature range: 0.008835005518220584\n",
      "Score for sampled target range values of feature range: -101.65340015414688\n",
      "Aggregate score: [ 5.54974238e-02  5.22199605e-02 -6.81841444e+14  5.53342046e-02]\n",
      "Aggregate score for target range: [ 8.81132915e-02  8.97237468e-02 -2.44377189e+15  4.58507518e-02]\n",
      "Aggregate shape: (1503424, 20) \n",
      "\n",
      "CSR Columns: 8000 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ee17519b7bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mup_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_decomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLSRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mreduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         print('Score for feature range:',\n\u001b[1;32m     20\u001b[0m               reduce.score(sample,train.iloc[index].deal_probability))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mx_loadings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# - subtract rank-one approximations to obtain remainder matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mXk\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_loadings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeflation_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"canonical\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;31m# - regress Yk's on y_score, then subtract rank-one approx.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reduce all CSR values in batches\n",
    "t = time.time()\n",
    "reduced = pd.DataFrame(index=train.index)\n",
    "low_col = 0\n",
    "# Start iteration with columns\n",
    "for col in np.arange(0,int(counts.shape[1]*1.05),2000):\n",
    "    # Limiting the edge case of the last values\n",
    "    if col > counts.shape[1]:\n",
    "        col = counts.shape[1]\n",
    "    up_col = col\n",
    "    \n",
    "    if up_col > low_col:\n",
    "        # Train PLSR on a large sample of those columns from CSR\n",
    "        print('CSR Columns:',low_col,up_col)\n",
    "        index = np.random.choice(len(train),size=int(4e5),replace=False)\n",
    "        sample = counts[index,low_col:up_col].toarray()\n",
    "        reduce = cross_decomposition.PLSRegression(n_components=5)\n",
    "        reduce.fit(sample,train.iloc[index].deal_probability)\n",
    "        print('Score for feature range:',\n",
    "              reduce.score(sample,train.iloc[index].deal_probability))\n",
    "        # Get scores for values of this target range\n",
    "        #tindex = np.random.choice(trange,size=int(3e5),replace=False)\n",
    "        tsample = counts[trange,low_col:up_col].toarray()\n",
    "        print('Score for sampled target range values of feature range:',\n",
    "              reduce.score(tsample,train.iloc[trange].deal_probability))\n",
    "\n",
    "        # Nested indexes iteration\n",
    "        components = pd.DataFrame()\n",
    "        low_idx = 0\n",
    "        for idx in np.arange(0,int(len(train)*1.1),int(3.1e5)):\n",
    "            # Limiting the edge case of the last values\n",
    "            if idx > len(train):\n",
    "                idx = len(train)\n",
    "            up_idx = idx\n",
    "\n",
    "            if up_idx > low_idx:\n",
    "                #print('Indexes:',low_idx,up_idx,'Columns:',low_col,up_col)\n",
    "                sample = counts[low_idx:up_idx,low_col:up_col].toarray()\n",
    "                #print('Sample shape:',sample.shape)\n",
    "                sample = reduce.transform(sample)\n",
    "                components = components.append(pd.DataFrame(sample))\n",
    "                low_idx = idx\n",
    "        components.reset_index(drop=True,inplace=True)\n",
    "        components.columns = ['col_{}-{}_{}'.format(low_col,up_col,i) for i in range(0,5)]\n",
    "        reduced = reduced.join(components)\n",
    "        print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced,y=train.deal_probability))\n",
    "        # Get scores for values of this target range\n",
    "        print('Aggregate score for target range:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange],y=train.iloc[trange].deal_probability))\n",
    "        print('Aggregate shape:',reduced.shape,'\\n')\n",
    "        low_col = col\n",
    "print('Minutes:',(time.time()-t)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced.to_pickle('upper_titles.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced = pd.read_pickle('lower_titles.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05240892 0.04901115 0.05157994 0.04980012]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[:,:12],y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.08078943 0.08111857 0.07536887 0.00922412]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange,:12],y=train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Round of Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08027798385712248\n"
     ]
    }
   ],
   "source": [
    "reduce = cross_decomposition.PLSRegression(n_components=5)\n",
    "reduce.fit(reduced.iloc[trange,:12],train.iloc[trange].deal_probability)\n",
    "print(reduce.score(reduced.iloc[trange,:12],train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced2 = reduce.transform(reduced.iloc[:,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.04948582 0.04635009 0.04874858 0.04723052]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced2,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.0810039  0.08118049 0.07604114 0.08167366]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced2[trange],y=train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced2 = pd.DataFrame(reduced2,columns=['upper_titles{}'.format(i) for i in range(0,5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced2.to_pickle('upper_titles_counts.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced2 = pd.read_pickle('upper_titles_counts.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate with Components of Other Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('../3.NLP StopWords NGrams/train_nlp_features7.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzero_counts = pd.read_pickle('zero_titles_counts.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_counts = pd.read_pickle('lower_titles_count.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = pd.read_pickle('categorical.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(fzero_counts)\n",
    "features = features.join(flow_counts)\n",
    "features = features.join(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.22725435 0.22227478 0.22561828 0.22613892]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05221368 0.05246749 0.05234117 0.05257644]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(reduced2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.2323735  0.22674674 0.23056228 0.23010993]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05186779 0.0521658  0.052007   0.05230665]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv =model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22822534533027566"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title_desc_0', 'title_desc_1', 'title_desc_2', 'title_desc_3',\n",
       "       'title_desc_4', 'title_desc_5', 'title_desc_6', 'title_desc_7',\n",
       "       'title_desc_8', 'title_desc_9', 'zero_titles0', 'zero_titles1',\n",
       "       'zero_titles2', 'zero_titles3', 'zero_titles4', 'zero_titles5',\n",
       "       'zero_titles6', 'zero_titles7', 'zero_titles8', 'zero_titles9',\n",
       "       'lower_titles0', 'lower_titles1', 'lower_titles2', 'lower_titles3',\n",
       "       'lower_titles4', 'cat_0', 'cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5',\n",
       "       'cat_6', 'cat_7', 'cat_8', 'cat_9', 'upper_titles0', 'upper_titles1',\n",
       "       'upper_titles2', 'upper_titles3', 'upper_titles4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_pickle('allfeatures.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
