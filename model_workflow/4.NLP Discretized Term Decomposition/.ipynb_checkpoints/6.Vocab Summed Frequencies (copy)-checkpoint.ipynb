{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import cyrtranslit\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection, ensemble, linear_model, cross_decomposition, feature_extraction, decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../../train.pkl',compression='zip')\n",
    "\n",
    "test = pd.read_pickle('../../test.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_stop = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_0 = train[train.deal_probability==0].index.tolist()\n",
    "i_low = train[(train.deal_probability>0)&(train.deal_probability<0.65)].index.tolist()\n",
    "i_up = train[train.deal_probability>=0.65].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Zero Summed Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = pd.read_pickle('vocabs_count.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41218\n"
     ]
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(\n",
    "    stop_words=ru_stop,\n",
    "    lowercase=False,\n",
    "    #max_features=8600,\n",
    "    #ngram_range=(1,2),\n",
    "    #min_df=0.0005,\n",
    "    #max_df=0.0005,\n",
    "    vocabulary=vocabs.low_voc.dropna()\n",
    ")\n",
    "vec.fit(train['title'].astype(str).tolist()+test['title'].astype(str).tolist())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts for train. CSR Matrix, tokens ordered alphabetically\n",
    "counts = vec.transform(train['title'].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 41218)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0281363e33744e2911aca212a59c043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1503424)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "max_count = counts.shape[0]\n",
    "\n",
    "f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "    \n",
    "sums = []\n",
    "for i in np.arange(max_count):\n",
    "    f.value += 1\n",
    "    sums.append(np.sum(counts[i].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced.to_pickle('zero_nlp.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced = pd.read_pickle('zero_titles.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.11578697 0.11145418 0.11558982 0.11406324]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=reduced.iloc[trange],y=train.iloc[trange].deal_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate with Components of Other Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('../3.NLP StopWords NGrams/train_nlp_features7.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzero_counts = pd.read_pickle('zero_titles_counts.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_counts = pd.read_pickle('lower_titles_count.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = pd.read_pickle('categorical.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(fzero_counts)\n",
    "features = features.join(flow_counts)\n",
    "features = features.join(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.22725435 0.22227478 0.22561828 0.22613892]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05221368 0.05246749 0.05234117 0.05257644]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.join(reduced2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.2323735  0.22674674 0.23056228 0.23010993]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate score: [0.05186779 0.0521658  0.052007   0.05230665]\n"
     ]
    }
   ],
   "source": [
    "print('Aggregate score:',model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv =model_selection.cross_val_score(\n",
    "            cv=4,estimator=linear_model.LinearRegression(),\n",
    "            X=features,y=train.deal_probability,\n",
    "            scoring=metrics.make_scorer(metrics.mean_squared_error)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22822534533027566"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title_desc_0', 'title_desc_1', 'title_desc_2', 'title_desc_3',\n",
       "       'title_desc_4', 'title_desc_5', 'title_desc_6', 'title_desc_7',\n",
       "       'title_desc_8', 'title_desc_9', 'zero_titles0', 'zero_titles1',\n",
       "       'zero_titles2', 'zero_titles3', 'zero_titles4', 'zero_titles5',\n",
       "       'zero_titles6', 'zero_titles7', 'zero_titles8', 'zero_titles9',\n",
       "       'lower_titles0', 'lower_titles1', 'lower_titles2', 'lower_titles3',\n",
       "       'lower_titles4', 'cat_0', 'cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5',\n",
       "       'cat_6', 'cat_7', 'cat_8', 'cat_9', 'upper_titles0', 'upper_titles1',\n",
       "       'upper_titles2', 'upper_titles3', 'upper_titles4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_pickle('allfeatures.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
