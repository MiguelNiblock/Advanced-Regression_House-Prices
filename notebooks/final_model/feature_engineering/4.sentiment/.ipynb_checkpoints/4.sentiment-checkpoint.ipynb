{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection, ensemble, linear_model, cross_decomposition, feature_extraction, decomposition\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "from polyglot.text import Text\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../../../train.pkl',compression='zip')\n",
    "test = pd.read_pickle('../../../test.pkl',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor(string):\n",
    "    punct = '~`!@#$%^&*()-+=|\\{}[]:;\",./'\n",
    "    for p in punct:\n",
    "        string = string.replace(p,' ')\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'train':train,'test':test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title & Description Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity on Train Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title...\n",
      "Cleaning train text.\n",
      "Polyglot parsing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N detected sentences: 1503424\n",
      "Actual N rows: 1503424\n",
      "Computing entity sentiments.\n",
      "0.0 percent done.\n",
      "0.05 percent done.\n",
      "0.1 percent done.\n",
      "0.15 percent done.\n",
      "0.2 percent done.\n",
      "0.25 percent done.\n",
      "0.3 percent done.\n",
      "0.35 percent done.\n",
      "0.4 percent done.\n",
      "0.45 percent done.\n",
      "0.5 percent done.\n",
      "0.55 percent done.\n",
      "0.6 percent done.\n",
      "0.65 percent done.\n",
      "0.7 percent done.\n",
      "0.75 percent done.\n",
      "0.8 percent done.\n",
      "0.85 percent done.\n",
      "0.9 percent done.\n",
      "0.95 percent done.\n",
      "1.0 percent done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train_title_polarity.sav']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute sentiment in a variable\n",
    "var = 'title'\n",
    "data = 'train'\n",
    "#####################################\n",
    "\n",
    "print(str(var)+'...')\n",
    "\n",
    "print('Cleaning text.')\n",
    "values = dic[data][var].fillna('').astype(str).apply(processor)\n",
    "values = '\\n'.join(values.tolist())\n",
    "\n",
    "print('Polyglot parsing.')\n",
    "text = Text(values)\n",
    "max_count = len(text.sentences)\n",
    "\n",
    "print('N detected sentences:',max_count)\n",
    "print('Actual N rows:',len(dic[data]))\n",
    "print('Computing entity sentiments.')\n",
    "means = []\n",
    "for i,s in enumerate(text.sentences):\n",
    "    step = 20\n",
    "    if i % int(len(dic[data])/portion) == 0:\n",
    "        print(np.round(i/len(dic[data]),decimals=4),'percent done.')\n",
    "    bag = []\n",
    "    for w in s.words:\n",
    "        bag.append(w.polarity)\n",
    "    means.append(np.mean(bag))\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[str(var)+'_polarity'] = means \n",
    "\n",
    "joblib.dump(df,'{}_{}_polarity.sav'.format(data,var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity on Test Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title...\n",
      "Cleaning train text.\n",
      "Polyglot parsing.\n",
      "N detected sentences: 508438\n",
      "Actual N rows: 508438\n",
      "Computing entity sentiments.\n",
      "0.0 percent done.\n",
      "0.05 percent done.\n",
      "0.1 percent done.\n",
      "0.15 percent done.\n",
      "0.2 percent done.\n",
      "0.25 percent done.\n",
      "0.3 percent done.\n",
      "0.35 percent done.\n",
      "0.4 percent done.\n",
      "0.45 percent done.\n",
      "0.5 percent done.\n",
      "0.55 percent done.\n",
      "0.6 percent done.\n",
      "0.65 percent done.\n",
      "0.7 percent done.\n",
      "0.75 percent done.\n",
      "0.8 percent done.\n",
      "0.85 percent done.\n",
      "0.9 percent done.\n",
      "0.95 percent done.\n",
      "1.0 percent done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test_title_polarity.sav']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute sentiment in a variable\n",
    "var = 'title'\n",
    "data = 'test'\n",
    "#####################################\n",
    "\n",
    "print(str(var)+'...')\n",
    "\n",
    "print('Cleaning text.')\n",
    "values = dic[data][var].fillna('').astype(str).apply(processor)\n",
    "values = '\\n'.join(values.tolist())\n",
    "\n",
    "print('Polyglot parsing.')\n",
    "text = Text(values)\n",
    "max_count = len(text.sentences)\n",
    "\n",
    "print('N detected sentences:',max_count)\n",
    "print('Actual N rows:',len(dic[data]))\n",
    "print('Computing entity sentiments.')\n",
    "means = []\n",
    "for i,s in enumerate(text.sentences):\n",
    "    step = 20\n",
    "    if i % int(len(dic[data])/portion) == 0:\n",
    "        print(np.round(i/len(dic[data]),decimals=4),'percent done.')\n",
    "    bag = []\n",
    "    for w in s.words:\n",
    "        bag.append(w.polarity)\n",
    "    means.append(np.mean(bag))\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[str(var)+'_polarity'] = means \n",
    "\n",
    "joblib.dump(df,'{}_{}_polarity.sav'.format(data,var))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
